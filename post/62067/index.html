<!DOCTYPE html>
<html
  lang="zh-cn"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了 - 区块大全
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="佚名" /><meta name="description" content="狂卷4个月，智谱AI开源第三代ChatGLM3！作为国内首个全线对标OpenAI产品线的公司，这波秀肌肉让人印象深刻。" />

  <meta name="keywords" content="区块大全, 区块链, 区块链资讯, 区块链快讯, 区块链新闻, 比特币行情" />






<meta name="generator" content="Hugo 0.120.4" />


<link rel="canonical" href="/post/62067/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css" integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow&#43;gqq15IXwkIrX5sNQGrI=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了" />
<meta property="og:description" content="狂卷4个月，智谱AI开源第三代ChatGLM3！作为国内首个全线对标OpenAI产品线的公司，这波秀肌肉让人印象深刻。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/62067/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-11-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-11-20T00:00:00+00:00" />

<meta itemprop="name" content="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了">
<meta itemprop="description" content="狂卷4个月，智谱AI开源第三代ChatGLM3！作为国内首个全线对标OpenAI产品线的公司，这波秀肌肉让人印象深刻。"><meta itemprop="datePublished" content="2023-11-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-11-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="7421">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"/>
<meta name="twitter:description" content="狂卷4个月，智谱AI开源第三代ChatGLM3！作为国内首个全线对标OpenAI产品线的公司，这波秀肌肉让人印象深刻。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">区块大全</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    


    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      区块大全
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      佚名
    
  </div>

  <div class="post-meta-time">
    <time datetime="2023-11-20">
      2023-11-20
    </time>
  </div>

  


  <div class="post-meta__right">
    <span class="post-meta-more">
        约 7421 字 -
        预计阅读 15 分钟
      </span>

    <div class="post-meta-category">
        <a href="/categories/%E5%85%B6%E5%AE%83%E6%96%87%E7%AB%A0/"> 其它文章 </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">币安网</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/binance?ref=githubio">注册链接</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/binance?ref=githubio">币安是全球领先的区块链生态系统，推出了一系列产品，其中包括最大的加密货币交易平台。我们的使命是在未来成为全球性加密货币基础架构供应商。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">欧易OKX</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/okx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/okx?ref=githubio">欧易是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">HTX火币</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/htx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/htx?ref=githubio">火币全球专业站，是火币集团旗下服务于全球专业交易用户的创新数字资产国际站，致力于发现优质的创新数字资产投资机会。</a>
            </td>
        </tr>
    </tbody>
</table>
<p>原文来源：<a href="https://mp.weixin.qq.com/s/j7_t4kHiK10zmIxiPwLNTg">新智元</a></p>
<p><img src="https://img.youtocoin.com/news/2023/1028/0_2iu3j6t1l6.png" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>图片来源：由<a href="https://www.wujieai.cc/">无界 AI</a>生成</p>
<p>全自研第三代基座大模型ChatGLM3，今日推出！</p>
<p>这是继6月份二代模型推出以来，智谱AI团队又一次对ChatGLM基座模型的优化。</p>
<p>此外，在10月27日的2023中国计算机大会（CNCC）上，智谱AI还开源了ChatGLM3-6B（32k）、多模态CogVLM-17B、以及智能体AgentLM。</p>
<p>ChatGLM3系列模型发布后，智谱成为国内唯一一个有对标OpenAI全模型产品线的公司。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/wf4ucpoenpn82wu" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>生成式AI助手智谱清言，也成为国内首个具备代码交互能力的大模型产品。</p>
<p>模型全自研，适配国产芯片，性能更强大，开源生态更开放。</p>
<p>作为最早入局大模型研究的企业，智谱AI率先交卷！</p>
<p>而且，智谱AI今年已累计完成超25亿人民币融资，美团、蚂蚁、阿里、腾讯……豪华的投资方名单，无不显出业内对智谱AI的强烈信心。</p>
<h2 id="瞄向gpt-4v的技术升级"><strong>瞄向GPT-4V的技术升级</strong></h2>
<p>当前，多模态视觉模型GPT-4V已经展现出强大的识图能力。</p>
<p>与此同时，瞄向GPT-4V，智谱AI这次也对ChatGLM3其他的能力，进行了迭代升级。其中包括，多模态理解能力的模型CogVLM，能够试图理解，刷新了10+个国际标准图文评测数据集SOTA。目前，CogVLM-17B已开源。</p>
<p>代码增强模块Code Interpreter能根据用户需求生成代码并执行，自动完成数据分析、文件处理等复杂任务。</p>
<p>网络搜索增强WebGLM，通过接入搜索增强，能自动根据问题在互联网上查找相关资料，并在回答时提供参考相关文献或文章链接。</p>
<p>另外，ChatGLM3的语义能力与逻辑能力也大大增强。</p>
<h3 id="6b版本直接开源"><strong>6B版本直接开源</strong></h3>
<p>值得一提的是，ChatGLM3一经发布，智谱AI直接向社区开源了6B参数的模型。</p>
<p>评测结果显示，与ChatGLM 2相比，以及国内同尺寸模型相比，ChatGLM3-6B在44个中英文公开数据集测试中，9个榜单中位列第一。</p>
<p>分别在MMLU提升36%、CEval提升33%、GSM8K提升179%、BBH提升126%。</p>
<p>其开源的32k版本ChatGLM3-6B-32K在LongBench中表现最佳。</p>
<p>另外，正是采用了最新的「高效动态推理+显存优化技术」，使得当前的推理框架在相同硬件、模型条件下，更加高效。</p>
<p>相较于目前最佳的开源实现，对比伯克利大学推出的vLLM，以及Hugging Face TGI的最新版本，推理速度提升了2-3倍，推理成本降低1倍，每千tokens仅0.5分，成本最低。</p>
<h3 id="自研agenttuning智能体能力激活"><strong>自研AgentTuning，智能体能力激活</strong></h3>
<p>更令人惊喜的是，ChatGLM3也带了全新的Agent智能体能力。</p>
<p>智谱AI希望，大模型能够通过API与外部工具更好交流，甚至通过智能体实现大模型交互。</p>
<p>通过集成自研的AgentTuning技术，能够激活模型智能代理能力，尤其在智能规划和执行方面，相比于ChatGLM 2提升1000%。</p>
<p>在最新的AgentBench上，ChatGLM3-turbo已经和GPT-3.5接近。</p>
<p>与此同时，智能体AgentLM也向开源社区开放。智谱AI团队希望的是，让开源模型达到甚至超过闭源模型的Agent能力。</p>
<p>这意味着，Agent智能体将开启国产大模型原生支持「工具调用、代码执行、游戏、数据库操作、知识图谱搜索与推理、操作系统」等复杂场景。</p>
<h3 id="15b3b同时发布手机就能跑"><strong>1.5B/3B同时发布，手机就能跑</strong></h3>
<p>想用手机去跑ChatGLM？可以！</p>
<p>这次ChatGLM3还专门推出了可在手机端部署的端测模型，分别有两个参数：1.5B和3B。</p>
<p>它能够支持Vivo、小米、三星在内的多种手机以及车载平台，甚至支持移动平台上CPU芯片的推理，速度可达20 tokens/s。</p>
<p>精度方面，1.5B和3B模型在公开基准评测上，性能直逼ChatGLM2-6B模型，快去试试！</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/b9i1e4179jjh0hb" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h2 id="新一代智谱清言全面上线"><strong>新一代「智谱清言」全面上线</strong></h2>
<p>正如ChatGPT背后有个强大的GPT-4模型，智谱AI团队的生成式AI助手「智谱清言」也得到了ChatGLM3的加持。</p>
<p>这个团队直播演示完，功能直接就上线了，主打的就是一个真诚！</p>
<p>测试地址：https://chatglm.cn/main/detail</p>
<h3 id="代码解释器"><strong>代码解释器</strong></h3>
<p>作为ChatGPT最受欢迎的插件之一，Advanced Data Analysis（原Code Interpreter）可以根据自然语言输入，以更加数学的思维分析问题，并同时生成恰当的代码。</p>
<p>如今，在全新升级的ChatGLM3加持下，「智谱清言」已成为国内首个具备Advanced Data Analysis能力的大模型产品，可支持图像处理、数学计算、数据分析等使用场景。</p>
<p>理工男的浪漫，或许只有「智谱清言」能懂。</p>
<p>虽然CEO张鹏现场表演画「红心」翻车，不过换个prompt一试，结果秒出。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/vfblrygg39l67sf" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>同样，升级后的ChatGLM3在数据分析方面也十分拿手。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/msdso0wirichmug" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>在一番解析之后，即可根据字段prompt的长度，画出长度分布的直方图。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/ggucdkh5mpikv1d" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h3 id="搜索增强"><strong>搜索增强</strong></h3>
<p>随着WebGLM大模型能力的加入，「智谱清言」现在也具有了搜索增强的能力——可以根据网上的最新资料总结出问题回答，并附上参考链接。</p>
<p>比如，最近iPhone 15迎来了一波降价，具体波动幅度有多大？</p>
<p>「智谱清言」给出的答案，效果还不错！</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/kf7b2fjrbdegzk0" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h3 id="图文理解"><strong>图文理解</strong></h3>
<p>CogVLM模型则提高了智谱清言的中文图文理解能力，取得了接近GPT-4V的图片理解能力。</p>
<p>它可以回答各种类型的视觉问题，并且可以完成复杂的目标检测，并打上标签，完成自动数据标注。</p>
<p>举个栗子，让CogVLM去识别图中有几个人。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/ep260qws4l4mww5" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p><img src="https://img.bibiqing.com/news/2023/1028/m349zn82s7k8fwl" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>加点难度，再给一张三个橘子垒起来的图，也能准确识别出数量。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/b5odvsp31sl2cv0" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p><img src="https://img.bibiqing.com/news/2023/1028/htrup8r2ceahj9k" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>内马尔、梅西、C罗，CogVLM认起来也是毫不含糊。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/en772jkf1mlq6uk" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>2只苹果和1只苹果相加的视觉数学题，CogVLM也能做对。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/r9sblam6zd7c6fs" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h2 id="glm-vs-gpt对标openai全线产品"><strong>GLM vs GPT：对标OpenAI全线产品！</strong></h2>
<p>从聊天对话应用ChatGPT、生成代码插件Code Interpreter，到文正图模型DALL·E 3、再到视觉多模态模型GPT-4V，OpenAI目前拥有一套完整的产品架构。</p>
<p>回看国内，能够同样做到产品覆盖最全面的公司，也就只有智谱AI了。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/5p1ge2ant0rzs19" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h3 id="对话chatgpt-vs-chatglm"><strong>对话：ChatGPT vs. ChatGLM</strong></h3>
<p>当红炸子鸡ChatGPT的介绍就不必多说了。</p>
<p>今年年初，智谱AI团队同样发布了千亿级的对话大模型ChatGLM。</p>
<p>借鉴了ChatGPT的设计思路，开发者在千亿基座模型GLM-130B中注入了代码预训练。</p>
<p>其实，早在2022年，智谱AI便向研究界和工业界开放了GLM-130B，这项研究也被ACL 2022和ICLR 2023顶会接收。</p>
<p>ChatGLM-6B和ChatGLM-130B模型，都在包含1T token的中英文语料上进行训练，使用了有监督微调（SFT）、反馈自助（feedback bootstrap）和人类反馈强化学习（RLHF）等方式。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/qr3nm18bdm2ymlv" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>ChatGLM模型能够生成符合人类偏好的答案。结合量化技术，用户可以在消费级显卡上进行本地部署（INT4量化级别下最低只需6GB显存），基于GLM模型可以在笔记本上运行自己的ChatGLM。</p>
<p>3月14日，智谱AI向社区开源了ChatGLM-6B，并且在第三方测评的中文自然语言、中文对话、中文问答及推理任务上获得第一。</p>
<p>与此同时，数百个基于ChatGLM-6B的项目或应用诞生。</p>
<p>为了更进一步促进大模型开源社区的发展，智谱AI在6月份的时候发布了ChatGLM2，千亿基座对话模型全系升级并开源，包括6B、12B、32B、66B、130B不同尺寸，能力提升，丰富场景。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/ebb504tescpp13i" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>ChatGLM 2的中文榜单上排名领先，截至2023年6月25日，ChatGLM2位居C-Eval榜单Rank 0，ChatGLM2-6B位居Rank 6。相比一代模型，ChatGLM 2在MMLU、C-Eval、GSM8K分别取得了16%、36%、280%的提升。</p>
<p>值得一提的是，在短短几个月内，ChatGLM-6B与ChatGLM2-6B共同得到广泛应用。</p>
<p>目前，GitHub上共收揽5万+ stars。并且，在Hugging Face上有10,000,000+下载量，四周趋势排行第一。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/gwpqonps9isi4zj" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>ChatGLM-6B：https://github.com/THUDM/ChatGLM-6B</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/q8mji8dlbvsrr20" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>ChatGLM2-6B：https://github.com/THUDM/ChatGLM2-6B</p>
<h3 id="搜索增强webgpt-vs-webglm"><strong>搜索增强：WebGPT vs. WebGLM</strong></h3>
<p>针对大模型「幻觉」这个问题，一般的解决思路就是结合搜索引擎中的知识，让大模型进行「检索增强」。</p>
<p>早在2021年，OpenAI就基于GPT-3微调了一个可以将搜索结果聚合的模型——WebGPT。</p>
<p>WebGPT通过模型人类搜索的行为，在网页中进行搜索寻找相关答案，并给出引用来源，让输出的结果有迹可循。</p>
<p>最重要的是，在开放域长问答上取得了优秀的效果。</p>
<p>在这个思路引导下， ChatGLM「联网版」模型WebGLM就诞生了，这是一个基于ChatGLM 100亿参数微调的模型，主打就是联网搜索。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/i5ulm82dt8wb3vn" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>论文地址：https://arxiv.org/abs/2306.07906</p>
<p>比如，当你想知道天空为什么是蓝色的。WebGLM立刻联网给出答案，并且附上了链接，增强模型回复的可信度。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/47iin782m3ne61a" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>从架构上来讲，WebGLM搜索增强系统涉及了三个重要的组件：检索器、生成器、评分器。</p>
<p>在基于LLM的检索器中分为了两个阶段，一是粗粒度的网络检索（搜索、获取、提取），另一个是细粒度蒸馏检索。</p>
<p>检索器整个过程中，时间主要消耗在获取网页步骤中，因此WebGLM采用了并行异步技术提高了效率。</p>
<p>引导生成器是核心，负责的是从检索器得到的参考网页中生成高质量的问题答案。</p>
<p>它利用大模型上下文推理能力，生成高质量的QA数据集，同时设计出校正和选择策略，来过滤出高质量的子集用于训练。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/wp5uunmc9c7nhs0" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>最后的评分器，是为了与人类偏好进行对齐，通过RLHF来为WebGLM生成的答案进行评分。</p>
<p>实验结果显示，WebGLM可以提供更加精确的结果，并能够高效完成问答任务。甚至，能够以100亿的参数性能，逼近1750亿参数的WebGPT。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/38b2mz03lop1st7" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>目前，这项研究已经被KDD 2023录用，同时智谱AI团队还开源了的能力和数据集。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/ylwy1w9mhlkgvyf" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>项目地址：https://github.com/THUDM/WebGLM</p>
<h3 id="图文理解gpt-4v-vs-cogvlm"><strong>图文理解：GPT-4V vs. CogVLM</strong></h3>
<p>今年9月，OpenAI正式解禁了GPT-4令人惊叹的多模态能力。</p>
<p>而在这背后提供支持的GPT-4V，对图像有着强大的理解能力，能够处理任意混合的多模态输入。</p>
<p>比如，它不能能看出图里的这道菜是麻婆豆腐，甚至还能给出制作的配料。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/lhtg1ng9odkv01z" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>10月，智谱了开源一种新的视觉语言基础模型CogVLM，可以在不牺牲任何NLP任务性能的情况下，实现视觉语言特征的深度融合。</p>
<p>不同于常见的浅层融合方法，CogVLM在注意力机制和前馈神经网络层中融入了一个可训练的视觉专家模块。</p>
<p>这一设计实现了图像和文本特征之间的深度对齐，有效地弥补了预训练语言模型与图像编码器之间的差异。</p>
<p>目前，CogVLM-17B是多模态权威学术榜单上综合成绩第一的模型，在14个数据集上取得了SOTA或第二名的成绩。</p>
<p>它在10个权威的跨模态基准测试中取得了最佳（SOTA）性能，包括NoCaps、Flicker30k captioning、RefCOCO、RefCOCO+、RefCOCOg、Visual7W、GQA、ScienceQA、VizWiz-VQA和TDIUC。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/9083z5rb9ro51s9" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>CogVLM之所以能取得效果的提升，最核心的思想是「视觉优先」。</p>
<p>之前的多模态模型通常都是将图像特征直接对齐到文本特征的输入空间去，并且图像特征的编码器通常规模较小，这种情况下图像可以看成是文本的「附庸」，效果自然有限。</p>
<p>而CogVLM在多模态模型中将视觉理解放在更优先的位置，使用5B参数的视觉编码器和6B参数的视觉专家模块，总共11B参数建模图像特征，甚至多于文本的7B参数量。</p>
<p>在部分测试中，CogVLM的表现甚至还超越了GPT-4V。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/74dfpshs0yet8tj" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>图中有4个房子，3个是完整可见的，还有1个只有放大才能看到。</p>
<p>CogVLM就能准确识别出这4个房子，而GPT-4V只能识别出3个。</p>
<p>这道题，考的是带文字的图片。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/ueah9fw10t8lypp" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>CogVLM忠实地描述了场景和相应的文字。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/lc5wunswsgnp1tt" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h3 id="文生图dalle-vs-cogview"><strong>文生图：DALL·E vs. CogView</strong></h3>
<p>OpenAI当前最强大的文生图模型，当属DALL·E 3了。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/oftfse5tofz3hqn" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>与之相对的是，智谱AI团队推出了基于Transformer的文本到图像通用预训练模型——CogView。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/1h8sys7iogjv287" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>论文地址：https://arxiv.org/abs/2105.13290</p>
<p>CogView的整体思路为，通过拼接文本特征和图像token特征，进行自回归训练。最终，实现了只输入文本token特征，模型即可连续生成图像token。</p>
<p>具体来说，首先将文本「一只可爱的小猫的头像」转换成token，这里用到了SentencePiece模型。</p>
<p>然后输入一只猫咪的图像，将图像部分通过一个离散化的自动解码器，转换成token。</p>
<p>紧接着，将文本和图像token特征进行拼接，然后输入到Transformer架构的GPT模型中学习生成图像。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/t1ysy9pwka6at0k" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>最后，训练完成后，在进行文本到图像的生成任务时，模型会通过计算一个Caption Score对生成结果进行排序，从而选择最匹配的结果。</p>
<p>对比了DALL·E和常见GAN的方案，CogView的结果均取得比较大的提升。</p>
<p>2022年，研究人员再次升级了文生图模型CogView2，效果直接对标DALL·E2。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/jfgnse3c2vbsec5" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>论文地址：https://arxiv.org/abs/2204.14217</p>
<p>相比CogView，CogView2的架构采用了分层Transfomer，以及并行自回归方式进行图像生成。</p>
<p>论文中，研究者预训练了一个60亿参数的Transformer模型——跨模态通用语言模型 (CogLM) ，并对其进行微调以实现快速超分辨率。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/lrbm7ecsr8vj8j5" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>实验结果显示，与DALL·E 2相比，CogView2生成结果同样有优势，并且还可以支持对图像进行交互式文本引导编辑。</p>
<p>紧接着同年11月，团队基于CogView2模型打造出了文本到视频生成模型CogVideo。</p>
<p>模型架构分为两个模块：第一部分基于CogView2，通过文本生成几帧图像。第二部分就是，基于双向注意力模型对图像进行插帧，进而生成帧率更高的完整视频。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/3w12cas7c9iuh6i" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>目前，以上所有模型全部开源了。清华出来的团队都这么直接且真诚吗？</p>
<h3 id="代码codex-vs-codegeex"><strong>代码：Codex vs. CodeGeeX</strong></h3>
<p>在代码生成领域，OpenAI早在2021年8月发布了全新升级的Codex，精通包括Python、JavaScript、Go、Perl、PHP、Ruby、Swift、TypeScript，甚至Shell等10多种编程语言。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/8vuo5jsos9hsov4" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>论文地址：https://arxiv.org/abs/2107.03374</p>
<p>用户只需给出简单的提示，就可以用自然语言让Codex自动编写代码。</p>
<p>Codex基于GPT-3进行训练，数据包含数十亿行源代码。并且，Codex可以支持比GPT-3长3倍以上的上下文信息。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/ct7tlw0z3s6cidb" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>作为国内的先行者，智谱在2022年9月开源了130亿参数的多编程语言代码生成、翻译及解释预训练模型CodeGeeX，并在之后被KDD 2023（Long Beach）接收。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/altskqsrl6ekt2v" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>论文地址：https://arxiv.org/abs/2303.17568</p>
<p>2023年7月，智谱又发布了更强，更快，更轻量的CodeGeeX2-6B，可以支持超过100种语言，权重对学术研究完全开放。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/5vbw4ae7o71v2i8" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>项目地址：https://github.com/THUDM/CodeGeeX2</p>
<p>CodeGeeX2基于全新的ChatGLM2架构，并专门针对各种与编程相关的任务进行了优化，如代码自动补全、代码生成、代码翻译、跨文件代码补全等。</p>
<p>得益于ChatGLM2的升级，CodeGeeX2不仅可以更好地支持中英文输入，以及最大8192序列长度，并且各项性能指标也取得了大幅提升——Python +57%, C++ +71%, Java +54%, JavaScript +83%, Go +56%, Rust +321%。</p>
<p>在HumanEval评测中，CodeGeeX2全面超越了150亿参数的StarCoder模型，以及OpenAI的Code-Cushman-001模型（GitHub Copilot曾使用的模型）。</p>
<p>除此之外，CodeGeeX2的推理速度也比一代CodeGeeX-13B更快，量化后仅需6GB显存即可运行，支持轻量级本地化部署。</p>
<p>目前，CodeGeeX插件已经可以在VS Code、 IntelliJ IDEA、PyCharm、GoLand、WebStorm、Android Studio等主流IDE中下载体验。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/skf14nt7ietyl1v" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<h2 id="国产大模型全自研"><strong>国产大模型全自研</strong></h2>
<p>大会上，智谱AI CEO张鹏一开始就抛出自己的观点——大模型元年并不是在ChatGPT引发LLM火爆热潮的今年，而是在GPT-3出世的2020年。</p>
<p>当时，刚刚成立一年的智谱AI便开始举全公司之力，ALL in大模型。</p>
<p>作为最早入局大模型研究的公司之一，智谱AI已经积累了充分的企业服务能力；作为在开源上「第一个吃螃蟹」的公司之一，ChatGLM-6B上线四周，就登上Hugging face趋势榜第一，获GitHub 5w+ stars。</p>
<p><img src="https://img.bibiqing.com/news/2023/1028/p3kbencarjc8mjs" alt="清华系ChatGLM3现场怼脸演示！多模态直逼GPT-4V，国产Code Interpreter来了"></p>
<p>ChatGLM3的发布，让智谱AI已构建起的全模型产品线更加强大。</p>
<p>在这个大模型行业战火纷飞的2023年，智谱AI再次站在聚光灯下，用全新升级ChatGLM3占据了先发优势。</p>
<p>参考资料：</p>
<p><a href="https://chatglm.cn/main/detail">https://chatglm.cn/main/detail</a></p>
<table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Gate芝麻开门</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/gateio?ref=githubio">平台介绍</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/gateio?ref=githubio">Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的加密货币交易平台，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bitget</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bitget?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bitget?ref=githubio">Bitget的背后是一群区块链技术的早期接受者，也是区块链未来发展的信仰者，一直致力于提供安全、一站式的交易解决方案，帮助用户更聪明地交易。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bybit</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bybit?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bybit?ref=githubio">Bybit通过数字资产与传统金融的结合，引领数字资产的生态发展。提供一流的流动性，致力于打造业内最安全、公平、高效及人性化的交易服务平台。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">派网</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/pionex?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/pionex?ref=githubio">派网提供多样化的量化交易机器人，用户可依照自身交易需求和策略选择最适合的机器人。 同时派网也提供合约交易与合约网格机器人，给予更方便的合约交易体验。</a>
            </td>
        </tr>
    </tbody>
</table>

        </div>

        
        



        
        


        <footer class="post-footer">
          


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/63506/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">浅论Restone：它不是Plasma 而是Optimium变体</span>
                <span class="prev-text nav-mobile">上一篇</span>
              </a>
            
              <a class="next" href="/post/63508/">
                <span class="next-text nav-default">去中心化储备稳定币概述：历史演变与模型分析</span>
                <span class="prev-text nav-mobile">下一篇</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      
        
      


      
      


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">文章目录</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#瞄向gpt-4v的技术升级"><strong>瞄向GPT-4V的技术升级</strong></a>
      <ul>
        <li><a href="#6b版本直接开源"><strong>6B版本直接开源</strong></a></li>
        <li><a href="#自研agenttuning智能体能力激活"><strong>自研AgentTuning，智能体能力激活</strong></a></li>
        <li><a href="#15b3b同时发布手机就能跑"><strong>1.5B/3B同时发布，手机就能跑</strong></a></li>
      </ul>
    </li>
    <li><a href="#新一代智谱清言全面上线"><strong>新一代「智谱清言」全面上线</strong></a>
      <ul>
        <li><a href="#代码解释器"><strong>代码解释器</strong></a></li>
        <li><a href="#搜索增强"><strong>搜索增强</strong></a></li>
        <li><a href="#图文理解"><strong>图文理解</strong></a></li>
      </ul>
    </li>
    <li><a href="#glm-vs-gpt对标openai全线产品"><strong>GLM vs GPT：对标OpenAI全线产品！</strong></a>
      <ul>
        <li><a href="#对话chatgpt-vs-chatglm"><strong>对话：ChatGPT vs. ChatGLM</strong></a></li>
        <li><a href="#搜索增强webgpt-vs-webglm"><strong>搜索增强：WebGPT vs. WebGLM</strong></a></li>
        <li><a href="#图文理解gpt-4v-vs-cogvlm"><strong>图文理解：GPT-4V vs. CogVLM</strong></a></li>
        <li><a href="#文生图dalle-vs-cogview"><strong>文生图：DALL·E vs. CogView</strong></a></li>
        <li><a href="#代码codex-vs-codegeex"><strong>代码：Codex vs. CodeGeeX</strong></a></li>
      </ul>
    </li>
    <li><a href="#国产大模型全自研"><strong>国产大模型全自研</strong></a></li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  

<a href="https://www.okbtc.cn/binance?ref=githubio" class="iconfont">
  <img src="/image/logo/binance.png" width="36px" height="36px" alt="binance">
</a>

<a href="https://www.okbtc.cn/okx?ref=githubio" class="iconfont">
  <img src="/image/logo/okx.png" width="36px" height="36px" alt="okx">
</a>

<a href="https://www.okbtc.cn/htx?ref=githubio" class="iconfont">
  <img src="/image/logo/htx.png" width="36px" height="36px" alt="htx">
</a>

<a href="https://www.okbtc.cn/gateio?ref=githubio" class="iconfont">
  <img src="/image/logo/gateio.png" width="36px" height="36px" alt="gateio">
</a>

<a href="https://www.okbtc.cn/bitget?ref=githubio" class="iconfont">
  <img src="/image/logo/bitget.png" width="36px" height="36px" alt="bitget">
</a>

<a href="https://www.okbtc.cn/bybit?ref=githubio" class="iconfont">
  <img src="/image/logo/bybit.png" width="36px" height="36px" alt="bybit">
</a>

<a href="https://www.okbtc.cn/pionex?ref=githubio" class="iconfont">
  <img src="/image/logo/pionex.png" width="36px" height="36px" alt="pionex">
</a>



</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2023
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        coin
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.8b200667dc4d9618390c41639250b9c29e57ce80707352fa95af6cb67cf2371a.js" integrity="sha256-iyAGZ9xNlhg5DEFjklC5wp5XzoBwc1L6la9stnzyNxo=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







  </body>
</html>
