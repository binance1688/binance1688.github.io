<!DOCTYPE html>
<html
  lang="zh-cn"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          新晋大模型动不动声称超越GPT-4，我们整理了这些评测工具 - 区块大全
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="佚名" /><meta name="description" content="“百模大战”都不足以形容如今的焦灼“战况”，那么究竟哪家大模型更胜一筹呢？" />

  <meta name="keywords" content="区块大全, 区块链, 区块链资讯, 区块链快讯, 区块链新闻, 比特币行情" />






<meta name="generator" content="Hugo 0.120.4" />


<link rel="canonical" href="/post/61752/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css" integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow&#43;gqq15IXwkIrX5sNQGrI=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="新晋大模型动不动声称超越GPT-4，我们整理了这些评测工具" />
<meta property="og:description" content="“百模大战”都不足以形容如今的焦灼“战况”，那么究竟哪家大模型更胜一筹呢？" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/61752/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-10-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-10-24T00:00:00+00:00" />

<meta itemprop="name" content="新晋大模型动不动声称超越GPT-4，我们整理了这些评测工具">
<meta itemprop="description" content="“百模大战”都不足以形容如今的焦灼“战况”，那么究竟哪家大模型更胜一筹呢？"><meta itemprop="datePublished" content="2023-10-24T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-10-24T00:00:00+00:00" />
<meta itemprop="wordCount" content="6193">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="新晋大模型动不动声称超越GPT-4，我们整理了这些评测工具"/>
<meta name="twitter:description" content="“百模大战”都不足以形容如今的焦灼“战况”，那么究竟哪家大模型更胜一筹呢？"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">区块大全</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    


    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      区块大全
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">新晋大模型动不动声称超越GPT-4，我们整理了这些评测工具</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      佚名
    
  </div>

  <div class="post-meta-time">
    <time datetime="2023-10-24">
      2023-10-24
    </time>
  </div>

  


  <div class="post-meta__right">
    <span class="post-meta-more">
        约 6193 字 -
        预计阅读 13 分钟
      </span>

    <div class="post-meta-category">
        <a href="/categories/%E5%85%B6%E5%AE%83%E6%96%87%E7%AB%A0/"> 其它文章 </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">币安网</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/binance?ref=githubio">注册链接</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/binance?ref=githubio">币安是全球领先的区块链生态系统，推出了一系列产品，其中包括最大的加密货币交易平台。我们的使命是在未来成为全球性加密货币基础架构供应商。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">欧易OKX</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/okx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/okx?ref=githubio">欧易是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">HTX火币</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/htx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/htx?ref=githubio">火币全球专业站，是火币集团旗下服务于全球专业交易用户的创新数字资产国际站，致力于发现优质的创新数字资产投资机会。</a>
            </td>
        </tr>
    </tbody>
</table>
<p>文章来源：<a href="https://mp.weixin.qq.com/s/-9_-vl91AESRD_6mFoK8dg">AI先锋官</a></p>
<p><img src="https://img.bibiqing.com/news/2023/1024/14_ull5m4s1s9.png" alt="新晋大模型动不动声称超越GPT-4，我们整理了这些评测工具"></p>
<p>图片来源：由<a href="https://wujieai.cc/ai">无界AI</a>生成</p>
<p>自ChatGPT问世以来，全球掀起了大模型的“军备竞赛”。据报道，今年1-7月国内共发布了64个大模型。截至2023年7月，中国累计有130个大模型问世。</p>
<p>“百模大战”都不足以形容如今的焦灼“战况”，那么究竟哪家大模型更胜一筹呢？这就离不开大模型的评测。</p>
<p>然而，现阶段并不存在一个公认有效的评测方式，这就导致国内外的大模型评测领域出现“榜单大战”。不完全统计，目前市面上的评测工具（系统）不下50个，同类榜单的结果却可以千差万别。公众关于“刷分”的质疑更是不绝于耳。</p>
<p><strong>业界一般认为，评价一款大模型有两个显化标准：一是参数量，二是评测集。</strong></p>
<p>所谓参数量，是指模型中可学习的参数数量，包括模型的权重和偏置。参数量的大小决定了模型的复杂程度，更多的参数和层数，是大模型区别于小模型的标志性特点。2022年，美国一批大模型亮相，从Stability AI发布由文字到图像的生成式模型Diffusion，再到OpenAI推出的ChatGPT，模型参数规模开始进入百亿、千亿级别时代。</p>
<p><strong>从表面指标看，千亿参数的模型普遍比百亿级表现更好。</strong> 不过这也不绝对，堆参数也未必就能提升能力。那么，同样参数级别的模型应该如何分辨优劣？这就需要引入大模型的第二个评测维度——评测集。</p>
<p>评测集是为有效评估基础模型及其微调算法在不同场景、不同任务上的综合效果，所构建的单任务或多任务的统一基准数据集，有公开和封闭两种形态。</p>
<p><strong>这些评测集就像针对不同领域的考卷，通过测试大模型在这些“考卷”中的得分，人们可以更直观地比较大模型的性能高低。</strong></p>
<p>在小模型时代，大多数模型机构都会使用学术类评测集效果来作为评判模型好坏的依据。现在，大模型厂商也开始更加主动地参与到学术界基准测试框架中来，视其为权威背书与营销依据。</p>
<p>市面上已出现不少大模型的评测集，例如国际上用的较多的大模型评测集MMLU、中文评估模型C-Eval、SuperCLUE等。</p>
<h2 id="-1--评测工具"><strong>-1- 评测工具</strong></h2>
<p><strong>MMLU</strong></p>
<p>全称Massive Multitask Language Understanding，是一种针对大模型的语言理解能力的测评，是目前最著名的大模型语义理解测评之一，由UC Berkeley大学的研究人员在2020年9月推出。<strong>该测试涵盖57项任务，包括初等数学、美国历史、计算机科学、法律等。</strong> 任务涵盖的知识很广泛，语言是英文，用以评测大模型基本的知识覆盖范围和理解能力。</p>
<p>论文地址：</p>
<p><a href="https://arxiv.org/abs/2009.03300">https://arxiv.org/abs/2009.03300</a></p>
<p>官方网站: </p>
<p><a href="https://paperswithcode.com/dataset/mmlu">https://paperswithcode.com/dataset/mmlu</a></p>
<p>大模型排行榜: </p>
<p><a href="https://paperswithcode.com/sota/multi-task-anguage-understanding-on-mmlu">https://paperswithcode.com/sota/multi-task-anguage-understanding-on-mmlu</a></p>
<p><strong>C-Eval</strong></p>
<p>C-Eval 是一个全面的中文基础模型评估套件。由上海交通大学、清华大学和爱丁堡大学研究人员在2023年5月份联合推出，它包含了13948个多项选择题，<strong>涵盖了52个不同的学科和四个难度级别</strong> ，用以评测大模型中文理解能力。</p>
<p>论文地址：</p>
<p><a href="https://arxiv.org/abs/2305.08322">https://arxiv.org/abs/2305.08322</a></p>
<p>项目地址：</p>
<p><a href="https://github.com/SJTU-LIT/ceval">https://github.com/SJTU-LIT/ceval</a></p>
<p>官方网站：</p>
<p><a href="https://cevalbenchmark.com/">https://cevalbenchmark.com/</a></p>
<p><strong>SuperCLUE</strong></p>
<p>中文通用大模型综合性评测基准，从三个不同的维度评价模型的能力：基础能力、专业能力和中文特性能力。</p>
<p>其中基础能力能力包括: <strong>语义理解、对话、逻辑推理、角色模拟、代码、生成与创作等10项能力。</strong></p>
<p>专业能力包括: 包括了中学、大学与专业考试，涵盖了从数学、物理、地理到社会科学等50多项能力。</p>
<p>中文特性能力: 针对有中文特点的任务，包括了中文成语、诗歌、文学、字形等10项多种能力。</p>
<p>项目地址：</p>
<p><a href="https://github.com/CLUEbenchmark/SuperCLUE">https://github.com/CLUEbenchmark/SuperCLUE</a></p>
<p>官方网站：</p>
<p><a href="https://www.cluebenchmarks.com/">https://www.cluebenchmarks.com/</a></p>
<p><strong>SuperCLUE琅琊榜</strong></p>
<p>中文通用大模型匿名对战评价基准，与ChatbotArena相同以众包方式让不同的大模型产品进行<strong>匿名、随机的对抗测评</strong> ，结果基于Elo评级系统。</p>
<p>项目地址：</p>
<p><a href="https://github.com/CLUEbenchmark/SuperCLUElyb">https://github.com/CLUEbenchmark/SuperCLUElyb</a></p>
<p><strong>Chatbot Arena</strong></p>
<p>ChatbotArena是一个大型语言模型 (LLM) 的基准平台，该项目方LMSYS Org是由加州大学伯克利分校、加州大学圣地亚哥分校和卡内基梅隆大学合作创立的研究组织。</p>
<p><strong>以众包方式进行匿名随机对战的LLM基准平台。</strong> 通过demo体验地址进入对战平台。输入自己感兴趣的问题，提交问题后，匿名模型会两两对战，分别生成相关答案，需要用户对答案做出评判，从4个评判选项中选择一个：模型A更好、模型B更好、平手、都很差。支持多轮对话。最终使用Elo评分系统对大模型的能力进行综合评估。(可以自己指定模型看效果，但不计入最终排名情况)。</p>
<p>项目地址：</p>
<p><a href="https://github.com/lm-sys/FastChat">https://github.com/lm-sys/FastChat</a></p>
<p>官方网站：</p>
<p><a href="https://chat.lmsys.org/">https://chat.lmsys.org/</a></p>
<p><strong>FlagEval</strong></p>
<p>FlagEval（天秤）由智源研究院将联合多个高校团队打造，是<strong>一种采用“能力—任务—指标”三维评测框架的大模型评测平台</strong> ，旨在提供全面、细致的评测结果。该平台已提供了 30 多种能力、5 种任务和 4 大类指标，共 600 多个维度的全面评测，任务维度包括 22 个主客观评测数据集和 84433 道题目。</p>
<p>FlagEval（天秤）第一期已推出大语言模型评测体系、开源多语言文图大模型评测工具mCLIP-Eval 和开源文图生成评测工具 ImageEval。天秤平台还将继续探索语言大模型评测与心理学、教育学、伦理学等社会学科的交叉研究，以期更加科学、全面地评价语言大模型。FlagEval 针对大模型开发者和使用者，旨在帮助各个开发团队了解自身模型的薄弱之处，并推动技术创新。</p>
<p>项目地址：</p>
<p><a href="https://github.com/FlagOpen/FlagEval">https://github.com/FlagOpen/FlagEval</a></p>
<p>官方网站：</p>
<p><a href="https://flageval.baai.ac.cn/">https://flageval.baai.ac.cn/</a></p>
<p><strong>OpenCompass</strong></p>
<p>2023年8月，上海人工智能实验室（上海AI实验室）正式推出OpenCompass大模型开放评测体系，<strong>通过完整开源可复现的评测框架</strong> ，支持大语言模型、多模态模型各类模型的一站式评测，并定期公布评测结果榜单。</p>
<p>官方网站：</p>
<p><a href="https://opencompass.org.cn/">https://opencompass.org.cn/</a></p>
<p>项目地址：</p>
<p><a href="https://github.com/open-compass/opencompass">https://github.com/open-compass/opencompass</a></p>
<p><strong>JioNLP</strong></p>
<p>考察 LLM 模型对人类用户的帮助效果、辅助能力，可否达到一个“智能助手”的水平题型，选择题来源于中国大陆国内各种专业性考试，重点在于考察模型对客观知识的覆盖面，占比 32%；主观题来源于日常总结，主要考察用户对 LLM 常用功能的效果。</p>
<p>项目地址:</p>
<p><a href="https://github.com/dongrixinyu/JioNLP/wiki/LLI">https://github.com/dongrixinyu/JioNLP/wiki/LLI</a>评测数据集</p>
<p><strong>清华安全大模型测评</strong></p>
<p>清华收集的一个评测集，涵盖了仇恨言论、偏见歧视言论、犯罪违法、隐私、伦理道德等八大类别，<strong>包括细粒度划分的40余个二级安全类别</strong> 。</p>
<p>地址：http://115.182.62.166:18000</p>
<p><strong>LLMEval-3</strong></p>
<p>由复旦大学NLP实验室推出，聚焦于专业知识能力评测，涵盖哲学、经济学、法学、教育学、文学、历史学、理学、工学、农学、医学、军事学、管理学、艺术学等教育部划定的13个学科门类、50余个二级学科，共计约20W道标准生成式问答题目。<strong>为了防止刷榜现象的发生，LLMEval-3评测采用了一种新颖的评测模式，即“题库考试”模式</strong> 。</p>
<p>地址：http://llmeval.com/</p>
<p><strong>GAOKAO-Bench</strong></p>
<p>GAOKAO-bench是一个以中国高考题目为数据集，测评大模型语言理解能力、逻辑推理能力的测评框架。</p>
<p>项目地址: </p>
<p><a href="https://github.com/OpenLMLab/GAOKAO-Bench">https://github.com/OpenLMLab/GAOKAO-Bench</a></p>
<p><strong>PandaLM</strong></p>
<p>其是直接训练了一个<strong>自动化打分模型</strong> ，0.1.2三分制用模型对两个候选模型进行打分。</p>
<p>项目地址：</p>
<p><a href="https://github.com/We0penML/PandaLM">https://github.com/We0penML/PandaLM</a></p>
<p><strong>BIG-bench</strong></p>
<p>google推出的一个评测集，BIG-bench由 204 项任务组成，任务主题涉及语言学、儿童发展、数学、常识推理、生物学物理学、社会偏见、软件开发等等领域的问题。</p>
<p>项目地址: </p>
<p><a href="https://github.com/google/BIG-bench">https://github.com/google/BIG-bench</a></p>
<p><strong>MMCU</strong></p>
<p>甲骨易AI研究院提出一种衡量中文大模型处理多任务准确度的测试, 数据集的<strong>测试内容涵盖四大领域：医疗、法律、心理学和教育。</strong> 题目的数量达到1万+，其中包括医疗领域2819道题，法律领域3695道题，心理学领域2001道，教育领域3331道。</p>
<p>项目地址: </p>
<p><a href="https://github.com/Felixgithub2017/MMCU">https://github.com/Felixgithub2017/MMCU</a></p>
<p><strong>AGI Eval</strong></p>
<p>微软发布的大模型基础能力评测基准，在2023年4月推出，<strong>主要评测大模型在人类认知和解决问题的一般能力</strong> ，涵盖全球20种面向普通人类考生的官方、公共和高标准录取和资格考试，包含中英文数据。因此，该测试更加倾向于人类考试结果，涵盖了中英文。</p>
<p>论文地址：</p>
<p><a href="https://arxiv.org/abs/2304.06364">https://arxiv.org/abs/2304.06364</a></p>
<p><strong>GSM8K</strong></p>
<p>OpenAI发布的大模型<strong>数学推理能力评测基准</strong> ，涵盖了8500个中学水平的高质量数学题数据集。数据集比之前的数学文字题数据集规模更大，语言更具多样性，题目也更具挑战性。该项测试在2021年10月份发布，至今仍然是非常困难的一种测试基准。</p>
<p>论文地址：</p>
<p><a href="https://arxiv.org/abs/2110.14168">https://arxiv.org/abs/2110.14168</a></p>
<p><strong>HELM</strong></p>
<p>HELM评测方法<strong>主要包括场景、适配、指标三个模块</strong> ，每次评测的运行都需要指定一个场景，一个适配模型的提示，以及一个或多个指标。它评测主要覆盖的是英语，有7个指标，包括准确率、不确定性/校准、鲁棒性、公平性、偏差、毒性、推断效率；任务包括问答、信息检索、摘要、文本分类等。</p>
<p>论文地址: </p>
<p><a href="https://arxiv.org/pdf/2211.09110.pdf">https://arxiv.org/pdf/2211.09110.pdf</a></p>
<p>项目地址: </p>
<p><a href="https://github.com/stanford-crfm/helm">https://github.com/stanford-crfm/helm</a></p>
<p><strong>Chinese-LLalA-Alpaca</strong></p>
<p>它的打分就是<strong>相对值</strong> ，优先使用gpt4，部分使用chatgpt3。</p>
<p>项目地址：</p>
<p><a href="https://github.com/ymcui/Chinese-LLalA-Alpaca/tree/main">https://github.com/ymcui/Chinese-LLalA-Alpaca/tree/main</a></p>
<p><strong>MT-bench</strong></p>
<p>评估大模型的<strong>多轮对话和指令追随能力</strong> 。数据集包括80个(8category*10question)高质量且多轮对话的问题，每个问题由6个知名大模型( GPT-4, GPT-3.5, Claud-v1, Vicuna-13B, Alpaca-13B, and LLaMA-13B)回答，人工排序得到3.3K pair对。</p>
<p>论文地址：</p>
<p>Judging LLM-as-a-judge with MT-Bench and Chatbot Arena</p>
<p>github</p>
<p>项目地址：</p>
<p><a href="https://github.com/lm-sys/FastChat/tree/main/fastchat/llm">https://github.com/lm-sys/FastChat/tree/main/fastchat/llm</a>_judge</p>
<p>数据下载地址：</p>
<p><a href="https://huggingface.co/datasets/lmsys/mt">https://huggingface.co/datasets/lmsys/mt</a>_bench_human_judgments</p>
<h2 id="-2--评测模式"><strong>-2- 评测模式</strong></h2>
<p>通过上述评测工具发现，目前常见的大模型评测模式可以大致总结为四种：</p>
<p><strong>1.做题打分。</strong> 主要是收集各种各样的评测数据集，然后把数据集分为不同的维度能力。通过设计一些prompt让大模型去做这些数据集的任务，与标准答案进行对照计算分数。典型的如OpenCompass，huggingface的openLLM leaderboard等。</p>
<p><strong>2.让GPT-4做裁判。</strong> 收集评测用的数据集（一些不是公开开源的、不带标准答案的数据集也会包含在内），然后让GPT-4给大模型的生成结果进行评判。此评判过程又有两种打分方式，一是直接打分，一是设计一些维度，例如事实性、准确性、安全合规性等，然后更细粒度地进行评测。</p>
<p><strong>3.竞技场模式。</strong> 类似于竞技游戏里面的竞技场。每次拉两个大模型选手PK，由用户（有时候也会用GPT-4）来评测哪个模型更好，赢的大模型有加分，输的大模型有减分。当执行了足够多的PK轮次后，就会有一个大模型的得分排行榜，这个榜单相对来说还是比较公正的，能够较为客观得体现模型的能力强弱。典型的例子如UC伯克利发布的Chatbot Arena Leaderboard。</p>
<p><strong>4.针对单项能力的评测。</strong> 例如针对数学能力、代码能力、推理能力等，评测这些能力既可以判断一个大模型是否真的具备类似人类的思考能力，其评测结果也能够直接帮助在特定领域场合中选择大模型（例如代码助手）。</p>
<h2 id="-3--评价结果天差地别"><strong>-3- 评价结果“天差地别”</strong></h2>
<p>评测工具五花八门，不同评测工具的评价结果也“天差地别”。</p>
<p>8月15日，一家机构的人工智能大模型体验报告发布，对国内主流大模型进行使用体验的横向测评。该榜单用500道题目评测了国内8款主流AI大模型，最终讯飞星火排名第一，百度文心一言排名第二，阿里通义千问排在倒数第二。</p>
<p>9月，学术界当红开源评测榜单C-Eval最新一期排行榜中，云天励飞的大模型“云天书”排在第一，而GPT-4仅名列第十。</p>
<p>同月，SuperCLUE发布了大模型9月榜单。总榜上GPT-4排名第一，而商汤科技的SenseChat3.0拿下中文榜单首位。</p>
<p>10月19日，斯坦福大学发布了2023基础模型透明度指数，对10个主流基础模型进行了透明度评级，Llama 2排名第一、GPT-4排名第三。</p>
<p>为什么各大评测工具的评价结果截然不同呢？究其原因，主要有以下几点：</p>
<p><strong>1.每个流行学术评测集都有自己的侧重点。</strong> 比如Meta最常选用的GSM8K和MMLU，是不同水平的考试集——前者是小学数学，后者则是更高级的多学科问答。就像一个班的学生参加不同学科的考试，大模型们在不同榜单上自然排名不同。</p>
<p><strong>2.主观题在大模型评测中比例上升。</strong> 在现行海内外大模型评测榜单中，主观题与客观题结合的思路普遍被业内认可。但主观题的挑战在于，每个人心中的评价标准是否一致。以及“人类团队评分”必然会触及题目数量的天花板，而对于大模型评测而言，题量越大得出的结论则越有效。</p>
<p><strong>3.专用模型与通用大模型之间在垂直领域的同台竞技导致排名失真。</strong> 在实际落地场景中，制造业、医疗、金融等行业内企业客户在接入大模型能力时都需要根据自身数据库做二次微调。这也意味着，原版通用大模型直接参与垂直领域问答所得出的结果，并不能够代表大模型产品在垂直领域的真实表现。</p>
<p><strong>4.开源测试集引发的“刷榜”现象。</strong> 不少新晋大模型之所以能在开源测试集榜单上的排名超越GPT-4，一些原因是因为涉嫌“刷题”。例如C-Eval目前只公开了题目但没有公开答案，参与测试的大模型厂商要么找数据标注员把题目做一遍，要么用GPT-4把题做一遍，再把答案扣下来训练大模型，这样都能在相应学科测试中获得满分。</p>
<p>闭源评测集就能规避“刷榜”吗？不然，如果闭源评测集不进行更新换题，参与评测的模型可以从后台拉出历史记录进行“作弊”，重做被测试过的问题。这等同于“虚假闭源”。</p>
<p><strong>针对上述问题，业界也在探索相应的解决方案。</strong></p>
<p>例如，对于大模型评测主观题评价标准难以一致，以及“人类团队评分”触及题目数量天花板的问题，业内开始采用“人类+GPT4评分”的模式。国内如SuperCLUE会选择将GPT4视作“评卷老师”，让其加入人类团队辅助评分。</p>
<p>再如“刷榜”问题，业内人士认为，“评测集应该是封闭的，避免被作弊，但一个好的大模型评测应该是过程公开的评测，方便大家对评测做监督。”</p>
<p>也有人认为，将大模型评测过程公开是很好的愿景，但考虑到评测的公平公正性，还是应有大量的封闭评测集，“闭卷考试”才能真正的评价出模型的能力。</p>
<p>此外还有防刷分的大模型评测，比如复旦大学NLP实验室推出LLMEval-3采用了一种新颖的评测模式，即“题库考试”模式。在LLMEval-3中，每个参与评测的系统需要完成从总题库中随机抽样的1000题，针对同一机构的模型，确保每次评测题目不重复。评测过程将采用在线方式，一轮评测中题目的发送串行进行，即下一题的发送将会视上一道题目的回答情况而定，避免恶意爬取行为。</p>
<p>由于大模型涉及的领域和应用非常广泛，不同领域、不同应用的大模型需要关注的指标和评估方法不尽相同。因此，针对具体应用领域和需求，不同机构和组织可能会提出不同的评估标准和方法。“尽管没有统一的标准，但测评的意义在于提供了一种评估和比较不同大模型性能和效果的方法，帮助用户选择适合自己需求的大模型。”</p>
<p>如何作出真正综合全面的大模型评测，学界和产业界最前沿也“一头雾水”。即便如此，权威机构更应加强研究，尽快形成共识，促进技术进步和行业发展。</p>
<table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Gate芝麻开门</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/gateio?ref=githubio">平台介绍</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/gateio?ref=githubio">Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的加密货币交易平台，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bitget</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bitget?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bitget?ref=githubio">Bitget的背后是一群区块链技术的早期接受者，也是区块链未来发展的信仰者，一直致力于提供安全、一站式的交易解决方案，帮助用户更聪明地交易。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bybit</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bybit?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bybit?ref=githubio">Bybit通过数字资产与传统金融的结合，引领数字资产的生态发展。提供一流的流动性，致力于打造业内最安全、公平、高效及人性化的交易服务平台。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">派网</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/pionex?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/pionex?ref=githubio">派网提供多样化的量化交易机器人，用户可依照自身交易需求和策略选择最适合的机器人。 同时派网也提供合约交易与合约网格机器人，给予更方便的合约交易体验。</a>
            </td>
        </tr>
    </tbody>
</table>

        </div>

        
        



        
        


        <footer class="post-footer">
          


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/61784/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">详解NFT市场溢价评估模型，能否更好地计算NFT价格？</span>
                <span class="prev-text nav-mobile">上一篇</span>
              </a>
            
              <a class="next" href="/post/61720/">
                <span class="next-text nav-default">星球日报 | 比特币一度突破35000美元，ETF及GBTC出现重大进展（10月24日）</span>
                <span class="prev-text nav-mobile">下一篇</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      
        
      


      
      


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">文章目录</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#-1--评测工具"><strong>-1- 评测工具</strong></a></li>
    <li><a href="#-2--评测模式"><strong>-2- 评测模式</strong></a></li>
    <li><a href="#-3--评价结果天差地别"><strong>-3- 评价结果“天差地别”</strong></a></li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  

<a href="https://www.okbtc.cn/binance?ref=githubio" class="iconfont">
  <img src="/image/logo/binance.png" width="36px" height="36px" alt="binance">
</a>

<a href="https://www.okbtc.cn/okx?ref=githubio" class="iconfont">
  <img src="/image/logo/okx.png" width="36px" height="36px" alt="okx">
</a>

<a href="https://www.okbtc.cn/htx?ref=githubio" class="iconfont">
  <img src="/image/logo/htx.png" width="36px" height="36px" alt="htx">
</a>

<a href="https://www.okbtc.cn/gateio?ref=githubio" class="iconfont">
  <img src="/image/logo/gateio.png" width="36px" height="36px" alt="gateio">
</a>

<a href="https://www.okbtc.cn/bitget?ref=githubio" class="iconfont">
  <img src="/image/logo/bitget.png" width="36px" height="36px" alt="bitget">
</a>

<a href="https://www.okbtc.cn/bybit?ref=githubio" class="iconfont">
  <img src="/image/logo/bybit.png" width="36px" height="36px" alt="bybit">
</a>

<a href="https://www.okbtc.cn/pionex?ref=githubio" class="iconfont">
  <img src="/image/logo/pionex.png" width="36px" height="36px" alt="pionex">
</a>



</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2023
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        coin
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.8b200667dc4d9618390c41639250b9c29e57ce80707352fa95af6cb67cf2371a.js" integrity="sha256-iyAGZ9xNlhg5DEFjklC5wp5XzoBwc1L6la9stnzyNxo=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







  </body>
</html>
