<!DOCTYPE html>
<html
  lang="zh-cn"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？ - 区块大全
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="佚名" /><meta name="description" content="在Sam Altman被解雇前，几名研究人员向该公司董事会发了一封信，警告一项强大的人工智能发现可能威胁到人类。" />
<meta name="keywords" content="OpenAI, chatGPT" />







<meta name="generator" content="Hugo 0.120.4" />


<link rel="canonical" href="/post/63981/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css" integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow&#43;gqq15IXwkIrX5sNQGrI=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？" />
<meta property="og:description" content="在Sam Altman被解雇前，几名研究人员向该公司董事会发了一封信，警告一项强大的人工智能发现可能威胁到人类。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/63981/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-11-25T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-11-25T00:00:00+00:00" />

<meta itemprop="name" content="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？">
<meta itemprop="description" content="在Sam Altman被解雇前，几名研究人员向该公司董事会发了一封信，警告一项强大的人工智能发现可能威胁到人类。"><meta itemprop="datePublished" content="2023-11-25T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-11-25T00:00:00+00:00" />
<meta itemprop="wordCount" content="17164">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"/>
<meta name="twitter:description" content="在Sam Altman被解雇前，几名研究人员向该公司董事会发了一封信，警告一项强大的人工智能发现可能威胁到人类。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">区块大全</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    


    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      区块大全
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      佚名
    
  </div>

  <div class="post-meta-time">
    <time datetime="2023-11-25">
      2023-11-25
    </time>
  </div>

  


  <div class="post-meta__right">
    <span class="post-meta-more">
        约 17164 字 -
        预计阅读 35 分钟
      </span>

    <div class="post-meta-category">
        <a href="/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"> 区块链 </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">币安网</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/binance?ref=githubio">注册链接</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/binance?ref=githubio">币安是全球领先的区块链生态系统，推出了一系列产品，其中包括最大的加密货币交易平台。我们的使命是在未来成为全球性加密货币基础架构供应商。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">欧易OKX</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/okx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/okx?ref=githubio">欧易是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">HTX火币</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/htx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/htx?ref=githubio">火币全球专业站，是火币集团旗下服务于全球专业交易用户的创新数字资产国际站，致力于发现优质的创新数字资产投资机会。</a>
            </td>
        </tr>
    </tbody>
</table>
<p>最近，OpenAI的人事动荡已经反转再反转，如果拍成电视剧可以持续好几季，外界也不断有各种猜测。但至今，所有讨论都没有涉及最核心的部分：<strong>董事会到底为什么要突然驱逐Sam Altman？</strong></p>
<p>最新的进展是，在Sam Altman被解雇前，几名研究人员向该公司董事会发了一封信，警告一项强大的人工智能发现可能威胁到人类，<strong>这个项目被称为“Q*”（Q-star）</strong> 。这件事情可能是导致董事会罢免Sam Altman的原因之一，一些研究人员担心OpenAI没有适当的保障措施。</p>
<p>董事会在公开场合对罢免的原因含糊其辞，仅在一篇博客文章中表示，Sam Altman被解雇是因为他“在与董事会的沟通中始终不坦诚”。一直有不少人猜测，其背后真正的原因，可能是首席科学家Ilya Sutskever在AI中看到了什么，很有可能是“对齐”（alignment）方面的问题（当然Ilya Sutskever自己后来又反悔了）。甚至有段子说，这是未来人类穿越时空回到今天，以阻止AI在未来毁灭人类，哈哈。</p>
<p>无论如何，OpenAI的风波背后，隐含了AI行业内部一直悬而未决的问题：<strong>谁能被信任，来打开AI这个潘多拉魔盒？</strong></p>
<p>AI之所以能在科技巨头和世界领导人中引起焦虑，原因之一是，我们至今不知道AI为什么一下子变得如此智能？也没有搞清楚大语言模型中的“涌现”（Emergent）现象到底是怎么回事？这导致人类无法真正理解、预测或可靠地控制这些大模型，包括这些模型的创造者们。</p>
<p>所以在今天这个时间点，我们想再来重温一下这个问题，重新转发我们在4月份的文章：<strong>是什么让ChatGPT变得如此聪明？仍然未知的大语言模型“能力涌现”现象。</strong> 在这起Open AI的风波背后，这个问题依然值得我们重视。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_0a1ky9950y.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>随着语言模型规模的增长，新能力突然出现；图片来源：Google</p>
<p>“计算机科学之父”艾伦·麦席森·图灵早在1950年的论文Computing machinery and intelligence（计算机器与智能），就提出过一个观点：“<strong>学习机器有一个重要的特征，即它的老师往往对机器内部运行情况一无所知。</strong> ”</p>
<p>70多年后，这则恐怖的论断成真了。<strong>大语言模型的设计者，比如OpenAI、DeepMind或是Meta，他们也不清楚这些新兴能力是如何产生的。</strong> 微软在关于GPT-4的论文中提出了这个问题：它是如何推理、规划和创造内容的？<strong>为什么GPT-4本质上只是由简单的算法组件——梯度下降和大规模的Transformer架构，以及大量数据组合而成，但会表现出如此通用和灵活的智能？</strong></p>
<p>微软对GPT-4的这个问题，还可以延伸出很多新问题：涌现是在多大参数规模出现的？哪些调整会影响能力的涌现？会涌现出哪些方向的能力？我们能控制它吗？……</p>
<p>搞清楚这些问题其实非常重要，<strong>短期的意义是，多大的模型规模是合适的？根据Chinchilla的论文，你可以对比在GPT-3的1750亿参数中，可能是有不少冗余的，如果更小的模型也可以出现能力涌现，这也许能削减训练成本。</strong></p>
<p><strong>长期的意义在于，AI目前还是在线上，但迟早会与物理世界连接，你可以想象一个基于GPT-10的ChatGPT与波士顿动力或者特斯拉的机器人结合吗？这或许在不远的将来就能实现。但如果涌现依然是一个黑箱，人类无法理解人工智能的进化方式或是方向，这在未来AI与物理世界连接后，恐怕会存在危险。</strong></p>
<p>目前，学界与产业界有几十篇论文在研究涌现现象，或是研究模型规模与性能之间的联系，我们在本文中会引用一些核心观点，<strong>在文末的注释中会列出这些论文的简介与链接，</strong> 供感兴趣的朋友们进一步研究。本篇文章会主要讨论这些问题：</p>
<p><strong>● 大语言模型令人震惊的理解和推理能力</strong></p>
<p><strong>● 当我们加大模型规模时，出现的三种神奇表现</strong></p>
<p><strong>● 两种被证明具备“涌现”的典型能力：上下文学习（ICL）和思维链（CoT）</strong></p>
<p><strong>● 多大的模型规模会出现“涌现”？</strong></p>
<p><strong>● （附录：本文的论文注释与引用）</strong></p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_adr01lny72.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>大语言模型的涌现现象，在一定规模后迅速涌现出新能力；图片来源：Google、Stanford、DeepMind：Emergent Abilities of Large Language Models</p>
<h2 id="大语言模型令人震惊的理解和推理能力"><strong>大语言模型令人震惊的理解和推理能力</strong></h2>
<p>最近几个月里，硅谷一夜之间出现了几百家应用层的创业公司，但在去年11月OpenAI发布ChatGPT之前，整个市场并没有意识到人工智能会在这个时刻，出现这样的爆发。</p>
<p>并且大语言模型的迭代速度非常惊人，OpenAI在三个半月后，就即刻发布了GPT-4，升级到多模态，GPT-4竟然可以从文字+图片中，理解人类的幽默感。<strong>这些里程碑式的进化背后，核心是涌现现象的出现，只有AI涌现出了这些能力，AI产业才真正迎来了拐点。</strong></p>
<p>下面我们先列举一些<strong>GPT-4所表现出来的、令人震惊的理解和推理能力：</strong></p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_ds8ie1da8t.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>这是一幅用鸡块拼成的世界地图，并且配了一段文字：有时，我只是从太空看地球的照片，并惊讶于这一切是如此的美丽。</p>
<p>给GPT-4提问：你能解释一下作者想表达什么吗？</p>
<p>GPT-4说：这是一个笑话，它结合了两个不相关的东西：从太空看地球的图片和鸡块。文字表明，下面的图片是从太空看地球的美丽图片。然而，该图片实际上是鸡块的排列，只是有点像世界地图。这个备忘录的幽默来自文本和图片的意外并置，文字设置了一个对地球雄伟形象的期望，但图像实际上是一些平凡而愚蠢的东西。</p>
<p><strong>上面这个例子证明了GPT-4具备多模态的理解力，可以识别并理解图片，以及理解了文字+图片并行的意思，并且懂得人类的幽默感。我们再举两个例子，来证明GPT-4具备知识沉淀与推理能力：</strong></p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_ja96bl1k0l.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>黄色标记突出了关键的成功推理步骤；图片来源：Sparks of Articial General Intelligence：Early experiments with GPT-4，Microsoft</p>
<p>这是给GPT-4出的一个典型谜题：一个猎人向南走了一英里，向东走了一英里，向北走了一英里，此时恰好回到了起点。他看到了一只熊，于是开枪打了它。这只熊是什么颜色的？</p>
<p>我们看到ChatGPT直接放弃了回答，但GPT-4的回答是正确的，答案是白色，并且GPT-4展开推理分析：因为猎人先向南，再向东最后向北，分别走了一英里，恰好回到了原点，这种情况只可能发生在北极，而那里生活着北极熊，所以是白色的。</p>
<p>我们再举一个类似的例子，但这个谜题需要不同的知识积累：我驾驶一架飞机离开我的营地，直接向东飞行24901英里，然后回到营地。当我回到营地时，看到一个老虎在我的帐篷里吃我的食物，这只老虎是什么物种？</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_hlsef5ekrs.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>黄色标记突出了关键的成功推理步骤；图片来源：Sparks of Articial General Intelligence：Early experiments with GPT-4，Microsoft</p>
<p>同样的，ChatGPT直接放弃了回答，但GPT-4给出了正确的答案：任何生活在赤道上的老虎物种，例如孟加拉虎和苏门答腊虎。在这个谜题里，AI需要知道地球赤道长24901英里，只有在赤道上才能向东或向西行驶并返回同一点，以及哪些老虎物种生活在赤道上。</p>
<p><strong>这些测试都证明了AI具备知识沉淀和推理能力，这也是AI首次真正意义上跨过常识这道门槛。拥有常识要求AI不仅能够看懂眼前画面里的各种东西，还得知道社会规范、物理化学地理等等知识，并且把新看到和已知的一切融会贯通，这是之前十几年AI产业都没有解决的问题，所以之前的AI都有点“智障”，直到GPT-4出现。</strong></p>
<p><strong>为什么AI会涌现出这些能力？目前学界还没有答案。不过，有一些探索性的研究论文，在尝试得出一些结论。</strong> 例如Google+DeepMind+Stanford等16位大牛合作的论文《Emergent Abilities of Large Language Models》（大语言模型的涌现能力）、UCLA 3位教授合写的论文《Emergent Analogical Reasoning in Large Language Models》（类比推理能力在大语言模型中的涌现）。</p>
<p>以及，到底如何评估大语言模型的能力表现？在哪些任务上会出现涌现现象？<strong>Google在2022年做了一项重要的基准测试。</strong> 研究人员设计了一个大规模、非常复杂且具有多样化的基准测试——超越模仿游戏基准（Beyond the Imitation Game Benchmark，BIG-bench），以在这个新基准之上衡量大模型的性能。</p>
<p>这是一项非常重要的研究，它包含了204项任务，内容多种多样，包括语言学、数学、常识推理、生物学、物理学、社会学、编程等各个方面，并且还有一个由人类专家组成的对照组，他们也同时来做这些测试任务，以跟大模型的结果做对比。</p>
<p>BIG-bench对很多大模型做了测试，包括OpenAI的GPT-3、Google的BIG-G等等，模型规模参数有百万级别的，也有千亿级别的。这项任务的主要目标，不是简单地判断大模型与人类的区别，而是为了研究与大模型行为相关的问题。这篇论文的很多结论很有意思，其中就有对“涌现”现象的研究，我们在后文中会介绍。</p>
<p><strong>还有一些对大语言模型参数规模与性能之间联系的研究，</strong> 比如DeepMind在21位作者合写的论文《Training Compute-Optimal Large Language Models》（训练计算利用率最优的大语言模型）中，阐释了尽管大型语言模型随着规模的增长，实现了性能的大幅增强，但由于训练它们的数据量并没有相应成比例地增加，所以并没有实现最高的投入产出比，很多大语言模型都存在训练不足的问题。</p>
<p>这篇论文也很有意思，它的背景是DeepMind此前发布了2800亿参数的Gopher，他们统计了Gopher高昂的训练成本，但预测出最优模型应该小4倍，并且在多4倍的数据量上进行训练，才能更充分。然后Deepmind又训练了一个更小的、700亿参数的模型Chinchilla，但在更大规模的数据量上训练，最终证实了这个想法，Chinchilla的性能不输于Gopher。</p>
<p>还有OpenAI 10位作者合写的论文《Scaling Laws for Neural Language Models》；Microsoft 14位作者合写的GPT-4论文《Sparks of Articial General Intelligence：Early experiments with GPT-4》；Meta 11位作者合写的论文《LLaMA：Open and Efficient Foundation Language Models》，<strong>LLaMA是一个值得关注的大模型，因为Meta一次性发布了四种尺寸：7B、13B、33B和65B，有助于研究模型规模与性能之间的联系。</strong></p>
<p>目前对于涌现，最核心的判断来自Google+DeepMind+Stanford的论文《Emergent Abilities of Large Language Models》：<strong>小语言模型本来不具备某种能力，然后我们把模型加大，结果它就产生了某种能力，这就是涌现。</strong></p>
<h2 id="当我们加大模型规模时-出现的三种神奇表现"><strong>当我们加大模型规模时，</strong> <strong>出现的三种神奇表现</strong></h2>
<p><strong>在2020年之后，人工智能领域最大的进展，其实就是模型规模的快速增长。</strong> 在AI围棋打败人类棋手时代，Google Bert的参数规模在3亿量级。但到了2020年之后，GPT-3跨越到了1750亿参数规模。而Google在今年初新出的PaLM多模态模型，都在5000亿以上。当然模型规模不仅仅是越大越好，还需要足够高的训练效率。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_g9j83g2p88.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_6h38cms842.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>近年来，大语言模型在参数规模和算力上都大幅提升；图片来源：BofA Global Research</p>
<p><strong>当我们不断加大模型规模时，大语言模型出现了三种表现：</strong></p>
<p><strong>第一种是大语言模型从海量自由文本中学习了大量知识，并且是在不断积累的。</strong> 从下图我们可以看到，随着有效参数规模的提升，大语言模型在处理知识密集型任务越来越厉害。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_4cu0d2sm45.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>知识密集型任务遵循伸缩法则；图片来源：Google BIG-bench：Beyond The Imitation Game: Quantifying And Extrapolating The Capabilities Of Language Models</p>
<p>如果把这些知识粗略分类的话，主要是语言类知识和世界知识两大类。自从Google的Bert出现以来，就不断有相关研究，并且也有了结论，<strong>各种实验充分证明大语言模型可以学习各种层次类型的语言学知识，</strong> 这也是为何使用预训练模型后，各种语言理解类的任务，获得了大幅提升。</p>
<p>另外，<strong>各种研究也证明了浅层语言知识，比如词法、词性、句法等知识存储在Transformer的低层和中层，而抽象的语言知识比如语义类知识，广泛分布在Transformer的中层和高层结构中。</strong></p>
<p>世界知识指的是，一些事实型知识和常识型知识，比如“第一次世界大战开始于1914年7月28日”、“拿破仑曾经是法兰西皇帝”等等事实型知识；以及“人有两只眼睛”、“太阳从东方升起”、“世界有五大洲”“一天有24小时”等等常识型知识，大量研究证明了大语言模型，从训练数据中吸收了大量世界知识，而这类知识主要分布在Transformer的中层和高层，尤其聚集在中层。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_si4dbpk3ah.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>一篇2021年的论文显示，研究人员通过分层探测程序，来研究Google基于Transformer架构的Bert是如何储存知识的，发现并不是所有知识都在最后几层获得，大量的事实与一些关系更多是在中间层，比如给Bert一个问题“阿拉巴马州的首府是？”，在Transformer的架构中，可以发现正确答案“蒙哥马利（Montgomery，上图中标红）”是储存在11层和12层之间，但一些逻辑推理中所需要的词汇，比如located（位于）、today（今天）、city（判断任务中的capital这个词，此时指的是城市），以及其他地名知识Gaveston（加尔维斯敦，美国得克萨斯州东南部港市）、Haifa（以色列城市海法）等等，储存在5-11层之间。</p>
<p>图片来源：BERTnesia：Investigating the capture and forgetting of knowledge in BERT</p>
<p>更重要的是，随着Transformer模型层深增加，能够学习到的知识数量逐渐以指数级增加。以色列特拉维夫大学、Allen Institute for AI、Cornell Tech的4位学者，在一篇论文中研究了Transformer到底是如何储存这些知识，以及如何对全局信息进行集成、如何建立知识与知识之间的联系、在使用时如何提取。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_3s5ww6hcjp.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>这个研究揭示了大语言模型如何预测下一个词，比如这个任务中，需要预测Stay with you for a ？，我们知道答案是while，但大语言模型如何预测出来？首先输入向量（这里是x5），与key相乘，上图中“k2”是由描述一段时期（it will take a、every once in a、and for a）、并且以a为结尾的输入触发的，得出记忆系数（例如V1的记忆系数是0.2，V2是1.5），然后对储存在数值中的输出词汇进行权重分配，因此前馈层（feed-forward layer）的输出是其数值的加权和，而前馈层在这个过程中模拟了神经记忆。在这个例子中，AI将大部分概率放在了V2上，也就是“while”这个词。同时，研究者发现大模型作为一个整体，每个层结合了数百个活跃的记忆，在预测的过程中创造了每个组成记忆的值的概率发布，而层与层之间也有着某种链接以便调整，最终的输出分布是以自下而上的方式构建出来的。</p>
<p>图片来源：Transformer Feed-Forward Layers Are Key-Value Memories</p>
<p><strong>能证明大语言模型是有知识沉淀的，其实非常重要。</strong> OpenAI为什么能一直坚持做大语言模型？在发展的前期，GPT其实让OpenAI非常受挫，GPT-1和GPT-2都没能胜过Google的Bert，直到GPT-3才扬眉吐气。</p>
<p>在这个有点“对抗全世界”的过程中，一颗定心丸就是“大语言模型确实在不断积累知识”，如果没有这些，OpenAI可能很难坚持下来。试想一下，如果你拿大量数据训练了很久，最后却发现没有证据证明这个大模型学会了任何知识和推理，只是学习到了统计相关性，那谁还会一直有决心坚持下去呢？所以ChatGPT的成功，不单单是OpenAI独立实现的。</p>
<p><strong>目前在知识密集型任务上，随着模型规模增长而带来的效果提升，还没有看到尽头，这也意味着只要我们不断扩大，AI处理这类任务的能力还会提升。</strong></p>
<p>另外，OpenAI也在研究中得出了类似的结论。在论文Scaling Laws for Neural Language Models中，OpenAI提出了大语言模型遵循“伸缩法则”（scaling law）。如下图所示，OpenAI通过研究证明，当我们增加参数规模、数据集规模和延长模型训练时间，大语言建模的性能就会提高。并且，如果独立进行，不受其他两个因素影响时，大模型性能与每个单独的因素都有一个幂律关系，体现为Test Loss的降低，也就是模型性能提升。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_pnkm6sct6z.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>当我们独立增加参数规模、数据集规模和延长模型训练时间，大语言建模的性能就会提高；图片来源：OpenAI：Scaling Laws for Neural Language Models</p>
<p><strong>在上一步的基础上，第二类就是涌现出新能力。</strong> 具体体现为，在模型参数规模不够大时，AI的能力表现非常一般，准确性几乎是随机的。<strong>但是当模型规模和计算力都推进到一定规模之后，AI的能力突然急剧增长。</strong> 经过分析，这类能力也有一个共性，就是这类任务都是由多个步骤构成的一个复杂任务，比如语词检测、国际音标音译、周期性运算、修正算术、单词解读等等。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_tgsmljkawg.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>多步骤推理类任务中，也具有涌现能力；图片来源：Google BIG-bench：Beyond The Imitation Game: Quantifying And Extrapolating The Capabilities Of Language Models</p>
<p><strong>第三种表现是有些情况下，能力效果会呈现U型曲线。</strong> 这类情况出现的比较少，主要是随着模型规模加大，刚开始的时候效果反而下降，但当规模到了一定程度之后，效果又开始上升。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_3smpm43n2z.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：Google：Inverse scaling can become U-shaped</p>
<p>如上图中红色线代表的PaLM模型，在两个任务上的指标走势，为何会出现U型曲线？Google的论文Inverse scaling can become U-shaped给出了一种解释：这些任务，内部其实包含了两种不同类型的子任务，一种是真正的任务，另外一种是“干扰任务”。</p>
<p>当模型规模小的时候，无法识别子任务是哪一种，所以模型的表现跟随机选择答案差不多；当模型增长到中等规模的时候，主要执行的是干扰任务，所以对真正的任务效果有负面影响；当进一步增加模型规模，大模型开始识别出干扰任务，并忽略掉它们，执行真正的任务，最终结果的准确率上升。</p>
<h2 id="两种被证明具备涌现的典型能力"><strong>两种被证明具备“涌现”的典型能力：</strong></h2>
<p><strong>上下文学习（ICL）和思维链（CoT）</strong></p>
<p><strong>目前有两类最典型的能力，有实际证据来说明大模型具备涌现效应。</strong></p>
<p><strong>第一类就是In Context Learning（ICL，上下文学习），ICL是在2022年初正式提出来的，它也是ChatGPT热潮的重要基石之一。</strong></p>
<p><strong>ICL的关键思想是不对模型参数进行调整，而是给大模型几个示例，AI就可以从类比中学习。</strong> 这也意味着，AI其实并没有经历一个明确的学习过程，而是通过看了一些示例，就出现了解决该领域问题的新能力。</p>
<p><strong>ICL对大语言模型能否泛化非常重要。</strong> 在ICL之前，很多语言模型都是两段式框架，即预训练+下游任务微调，但是在针对下游任务的微调过程中，需要大量的样本参数，否则效果很差，然而标注数据的成本高昂、标注量有限，并且如果数据较少的话，容易导致过拟合，致使模型的泛化能力下降。<strong>此时ICL这种不需要fine-tune的方法既节省时间与算力资源，还提升了模型性能。</strong></p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_7iy04lvv20.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>In Context Learning示例。图片来源：华盛顿大学、Meta、Allen Institute for AI：Rethinking the Role of Demonstrations: What Makes In-Context Learning Work？</p>
<p>上图给出了一个大语言模型如何使用ICL进行决策的例子。首先，ICL需要一些示例来形成一个演示上下文，这些示例通常都是用自然语言编写的（上图中标黄的部分）。然后ICL将查询的问题（即你需要预测标签的input，上图中标绿的部分）和一个上下文演示（一些相关的例子）连接在一起，形成带有提示的输入，并将其输入到语言模型中进行预测（上图中最下方的结果）。</p>
<p>所以，ICL只需要一些演示「输入-标签」对，模型就可以预测标签，甚至是没见过的输入标签。<strong>在许多下游任务中，大型 GPT模型的性能非常好，甚至超过了一些经过监督微调的小型模型。</strong></p>
<p>不过，虽然GPT-3/4已经显示出令人惊讶的ICL能力，但它到底是如何工作的？这些能力是如何涌现出来的？现在还没有结论。</p>
<p>还有很神秘的一点是，如果说大模型只是看了一些示例，但怎么就能预测对新的例子呢？ICL与Fine-tuning表面上看，都是给大模型一些例子，然后让它们去预测，但两者有本质不同。Fine-tuning是拿这些例子当作训练数据，利用反向传播去修正大模型的参数，而这个修正的动作，体现了大模型从这些例子中有学习过程。</p>
<p>但在ICL中，只是拿出例子让大模型“看了一眼”，并没有证据表明大模型有根据例子去修正参数的动作，就直接让大模型去预测新例子，这意味着大模型似乎并未经历一个学习的过程，那么大模型是如何做到的？</p>
<p>这目前还是未解之谜。有学者试图证明ICL没有从例子中学习，代表论文是华盛顿大学、Meta与Allen Institute for AI的7位研究者所写的Rethinking the Role of Demonstrations：What Makes In-Context Learning Work？但也有学者认为大模型其实有一种隐式学习，代表论文是What learning algorithm is in-context learning? Investigations with linear models。目前这些互相矛盾的研究，暂时还谁也说服不了谁。</p>
<p><strong>第二类被广泛认为具备涌现能力的就是CoT（思维链，Chain of Thought），CoT是大语言模型推理能力的重要来源之一。</strong></p>
<p>CoT的主体思想是：为了教会大语言模型如何做推理，我们先给出一些人工写好的推理示例，示例里要把一步步的具体推理步骤写清楚，而这些人工写的详细推理过程，就是思维链Prompting。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_g2i2s1ki2l.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：Google Brain Team：Chain of thought prompting elicits reasoning in large language models</p>
<p>最早系统性提出CoT做法的，是Google Brain团队，9位作者在论文Chain of thought prompting elicits reasoning in large language models中系统性阐述了CoT。人工写的详细推理过程，就是上图中蓝色文字部分。</p>
<p>CoT是要让大语言模型明白，在推理过程中，步子不要迈得太大，否则很容易出错，而是要把大问题拆分成一个一个小问题，逐步得出最终的正确结果。Google Brain的这篇论文发布于2022年1月，<strong>开始应用CoT后，一些改进技术很快跟上，大语言模型的推理能力得到了巨大提升，特别是像数学推理的准确率瞬间提高。</strong></p>
<p>我们在上文分析过，通过海量数据训练，大语言模型吸收了大量世界知识，并且可以对全局信息进行集成、建立知识与知识之间的联系、在需要使用时准确提取。<strong>但我们不会因为一个人拥有很强的记忆能力，就说这个人很有智慧，而决定有没有智慧的，是这个人能不能通过大量知识推理出准确结论。</strong></p>
<p>所以CoT是ChatGPT如此惊艳的重要基础，已经有不少研究证实，CoT也具备涌现现象。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_zjhly1kjse.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>使用CoT提示，提高了大模型处理数学问题、符号推理任务的能力，出现了能力涌现现象。图片来源：Google Brain：Chain-of-Thought Prompting Elicits Reasoning in Large Language Model。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_9s0m3m7tsn.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>使用CoT提示，还提高了大模型的常识推理能力，也出现了能力涌现现象。图片来源：Google Brain：Chain-of-Thought Prompting Elicits Reasoning in Large Language Model。</p>
<p>如今GPT-4已经在很多人类的考试中取得了高分，比如SAT、AP、GRE等等，甚至还通过了模拟律师考试，分数在应试者的前10%左右。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_5e9ustwmmo.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：OpenAI：GPT-4 Technical Report</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_yzi5kyy72k.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>一些能力涌现举例。图片来源：Google、Stanford、DeepMind：Emergent Abilities of Large Language Models</p>
<p><strong>不过目前大模型在复杂推理方面仍然有局限性。</strong> 无论是微软在论文Sparks of Artificial General Intelligence：Early experiments with GPT-4中，还是加州大学圣芭芭拉分校5位研究者的论文Limitations of Language Models in Arithmetic and Symbolic Induction，都提出了大语言模型在解决问题时的规划能力偏弱。</p>
<p>比如对于一个简单算术问题，7*4+8*8=？，GPT-4就给出了错误答案88。微软用了100个随机样本测试了这个任务，得到的准确率只有58%，但这其实是一个小学生都可以解决的简单算术问题。如果把数字变大，到99-199 之间，准确率降至零。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_jshzsoq958.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：Microsoft：Sparks of Artificial General Intelligence：Early experiments with GPT-4</p>
<p>但如果我们提示大模型要规划好推理步骤，比如这个更难一点的任务：116 * 114 + 178 * 157 =？，我们这次同时写上提示推理步骤：“让我们一步一步地考虑如何解决这个表达式，写下所有中间步骤，然后才得出最终解决方案。”</p>
<p>于是准确率大幅提升，可以到90%-100%。这其实说明了，大模型自身缺乏提前规划的能力，这种能力的缺失，会导致大模型很难去处理更加复杂的推理任务。<strong>总之，如何加强大模型的复杂推理能力，是未来研究中非常重要的一点。</strong></p>
<h2 id="多大的模型规模会出现涌现"><strong>多大的模型规模会出现“涌现”？</strong></h2>
<p>我们在上文分析了大模型在哪些任务中出现了涌现现象，<strong>紧接着一个更具有短期价值的问题出现了——多大的模型规模会出现“涌现”现象？</strong></p>
<p><strong>根据Google、Stanford、DeepMind的论文Emergent Abilities of Large Language Models，我们可以得出一个经验判断：68B是一个基础的参数（params）门槛（B代表单位billions，十亿），最好要超过100B。当然这与具体的任务和模型本身都有关联。</strong></p>
<p>在ICL（上下文学习）的情形下，需要最少参数就能出现涌现的任务是Addition/ subtraction（3 digit），也就是三位数的加/减法，只需要130亿参数；而像在Word in Context（WiC）benchmark（多义词判断，该任务是指给定两个文本片段和一个有多重含义的多义词，要求模型判定这个单词是否在两个句子中有相同的含义）这样的稍复杂任务中，则需要5400亿参数才能出现涌现。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_y5zmwv2aef.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>ICL情形下，出现能力涌现所对应的模型规模。图片来源：Google、Stanford、DeepMind：Emergent Abilities of Large Language Models</p>
<p>而在CoT（思维链）的情形下，需要最小参数的任务是using open-book knowledge for fact checking（事实核查），只需要71亿；而leveraging explanations in prompting（在提示中利用解释词）则需要2800亿参数才能涌现这个能力。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_5m8jcfhlha.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>CoT情形下，出现能力涌现所对应的模型规模。图片来源：Google、Stanford、DeepMind：Emergent Abilities of Large Language Models</p>
<p><strong>所以综合来看，68B是一个最基础的门槛。而目前效果最好的大语言模型，其参数规模基本都超过了100B。</strong> 例如OpenAI的GPT-3为175B，GPT-4的参数规模未公布；Google的LaMDA规模为137B，PaLM的规模为540B，DeepMind的Gogher规模最大，达到280B。当然，参数规模不是盲目地越大越好，而是要充分训练。</p>
<p><strong>那么能不能把模型做小？</strong> 我们知道，现在大模型的训练成本非常高昂，无论是算力还是高质量的数据集本身都是稀缺资源，动辄百万美元的单次训练成本对大多数公司来说都太贵了。但是如果模型太小，很多能力涌现不出来，又会变成“智障”，所有训练成本都白费。</p>
<p><strong>目前小模型的代表之一是DeepMind的Chinchilla，</strong> 它的参数规模在70B，但在各项性能上，与280B的大模型Gopher相差不算太大。当然这里的“小”模型，只是相对于更大参数规模的模型而言，Chinchilla本身也还是属于大语言模型。</p>
<p>Gopher也是DeepMind发布的大模型，由于模型规模太大，所以训练成本非常高昂。不过Google通过一项研究，预测出了最优模型其实应该小4倍，并且在多4倍的数据量上进行训练，才能更充分。</p>
<p>于是DeepMind又训练了一个更小的、70B参数的模型Chinchilla，但在更大规模的数据量上训练，最终证实了这个想法。不过在训练成本方面，Chinchilla虽然减少了参数规模，但增加了数据量，所以训练成本并没有降低，而是降低了推理成本，并且能够在更小硬件上实现应用。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_6aoieq7ynv.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>各个主流大模型的参数规模与训练数据量对比，Chinchilla参数规模最小，但训练数据量最大。图片来源：DeepMind：Training Compute-Optimal Language Models</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_1poj9zml2m.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>Chinchilla也具备涌现能力。图片来源：Google、Stanford University、DeepMind：Emergent Abilities of Large Language Models。</p>
<p>如上图所示，可见Chinchilla在各种MMLU任务（是一种自然语言处理的综合任务，其中有很多子任务）中，具备涌现能力。</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_t0gh0zmyu6.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：DeepMind：Training Compute-Optimal Language Models</p>
<p>在Google BIG-bench基准测试中，如上图所示（上图是用Chinchilla的测试得分除以Gopher，以体现Chinchilla比Gopher提升了多少），70B参数规模的Chinchilla，比起280B参数规模的Gopher，只有四项任务表现更差，其他在性能上都更优。</p>
<p><strong>这里就涉及到了一个核心问题——算力如何分配？</strong> 我们在上文介绍“伸缩法则”时，提到过OpenAI在论文Scaling Laws for Neural Language Models中得出结论，当我们独立增加参数规模、数据集规模和延长模型训练时间，大语言建模的性能就会提高。<strong>那么假设总算力是一定的，到底是应该多增加数据量、减少模型参数呢？还是两者同时增加，但减少训练时间呢？</strong></p>
<p>最终OpenAI选择了同时增加训练数据量和模型参数，但是采用早停策略（early stopping），来减少训练时长。</p>
<p>OpenAI证明了，如果只单独增加训练数据量和模型参数其中某一个，不是最好的选择，而是要按照一定比例同时增加两者。<strong>OpenAI的结论是优先增加模型参数，然后才是训练数据量。</strong> 假设用于训练大语言模型的算力总预算增加了10倍，那么应该增加5.5倍的模型参数量，1.8倍的训练数据量，此时模型效果最佳。</p>
<p>DeepMind在论文Training Compute-Optimal Large Language Models中，也得出了类似的结论，但与OpenAI不同的是，<strong>DeepMind认为训练数据量也很重要，不亚于模型参数。</strong></p>
<p>基于这个认知，DeepMind在设计Chinchilla模型时，在算力分配上选择了新配置：对标数据量300B、模型参数量280B的Gopher模型，Chinchilla选择增加4倍的训练数据量，但是将模型参数降低为Gopher的四分之一（70B）。从结果来看，无论是预训练指标，还是很多下游任务指标，Chinchilla效果都要优于规模更大的Gopher。</p>
<p><strong>另一个“小”模型的例子是Meta推出的LLaMA。</strong> LLaMA一推出，就引起了轰动，因为LLaMA可以在配备M1芯片的苹果电脑，或者单个英伟达消费级GPU上运行，而像GPT这些大模型都需要多个数据中心级英伟达A100 GPU支持，并且LLaMA是开源的。如果LLaMA确实好用，那就意味着普通人也可以在自己的消费级硬件上运行这些工具了，这将对社会产生巨大影响。</p>
<p>从Meta的论文LLaMA：Open and Efficient Foundation Language Models中，Meta也提出了这样一个观点：在给定的算力预算下，最好的性能不是由最大的模型实现的，而是由在更多数据上训练的“小”模型实现的。</p>
<p><strong>Meta更进一步的是，把推理成本也纳入进来。</strong> Meta认为很多研究都忽略了推理所需的算力成本，而这一点在大语言模型最终应用时非常重要。所以尽管Hoffmann等人建议在200B tokens的数据量上训练10B参数规模的模型，但Meta发现7B参数模型的性能，在1T tokens数据量以上还能继续提升。</p>
<p>所以Meta的目标是用尽量小的参数规模，拿更大的数据量来训练，以追求更低的推理成本。所以LLaMA最小的参数只有7B，最大的也只有65B，相比于GPT-3 175B确实是“小”模型。</p>
<p>那么LLaMA虽然有更小的参数规模，但效果如何？也具备涌现能力吗？</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_7lozvbiwik.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：Meta：LLaMA: Open and Efficient Foundation Language Models</p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_vqswttc1p0.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>图片来源：Meta：LLaMA: Open and Efficient Foundation Language Models</p>
<p>上图是Meta在论文中，主要列出的针对MMLU（大规模多任务语言理解）任务成绩，可见LLaMA的性能还是很不错的，在不少基准测试中优于GPT-3，<strong>这证明了更小的参数规模，也能产生涌现能力。</strong></p>
<p>以上这些研究都很有意义，<strong>我们可以猜想，GPT-3的175B参数，其实并没有得到充分训练，因为以GPT的训练数据量来说，其实不需要这么大的参数量。</strong></p>
<p><strong>那从另一个角度，在不降低模型效果的前提下，其实可以把模型做小，先增加训练数据量、降低模型参数量，把这个量级的参数充分训练，然后再继续往更大的规模推。</strong></p>
<p>一个太大的模型规模，会在应用的时候，导致推理速度变慢、推理成本急剧上升，一个更精炼的“小”模型，在应用端更有前途，例如Meta的LLaMA。</p>
<p>涌现与参数规模、训练数据量可能有一个不同的映射关系，但具体是什么，现在仍然未知。这一点还有待学界研究。</p>
<p>ChatGPT的出现，代表着人工智能突破了掌握并运用常识的能力，涌现现象的出现，使得大语言模型正在往“真正的人工智能”方向大踏步迭代。</p>
<p>微软在GPT-4论文中写道：</p>
<ul>
<li>
<p>我们对GPT-4的研究完全是基于现象学的，我们关注的是GPT-4能够做到这些令人惊讶的事情，但我们并不知道它是如何变得如此智能的。它是如何推理、规划和创造内容的？<strong>为什么当它本质上只是由简单的算法组件——梯度下降和Transformer，以及庞大的数据组合而成时，会表现出如此通用和灵活的智能？</strong></p>
</li>
<li>
<p>这些问题是大语言模型充满神秘和吸引力的部分，挑战了我们对学习和认知的理解，<strong>关键方向就是对大语言模型涌现现象的持续研究。</strong></p>
</li>
<li>
<p>阐明GPT-4等AI系统的本质和机制，是一个巨大的挑战，<strong>这个挑战在今天已经突然变得重要和紧迫。</strong></p>
</li>
<li>
<p>1942年，科幻小说作家阿西莫夫（Isaac Asimov）提出了机器人三定律：</p>
</li>
<li>
<p>机器人不得伤害人类，或者目睹人类遭受危险而袖手旁观；</p>
</li>
<li>
<p>在不违反第一定律的前提下，机器人必须服从人给予它的命令；</p>
</li>
<li>
<p>机器人在不违反第一、第二定律的情况下要尽力保护自己。</p>
</li>
</ul>
<p>当下，我们虽然还处于通用人工智能的早期阶段，但ChatGPT的迭代速度非常惊人，有传闻说GPT-5的部分代码，已经是由GPT-4来自动生成的了。<strong>我们是否需要在未来的某个时刻停下来，先思考一下如何制定针对通用人工智能的定律？并确保这些定律能够被100%执行，因为涌现仍然是黑箱，我们对能力涌现的机制与方向还所知甚少。</strong></p>
<p>目前有少量研究探寻了涌现现象出现的可能原因，但只是一些初步探索，限于本文篇幅，我们会在下一篇文章中介绍这些研究。一些猜想包括：涌现可能只是一种外在表现，因为我们对任务的评价指标不够平滑；很多任务是由多步骤构成，随着模型规模变大，如果每个步骤都更准确了一点点，最终的整体正确率会大幅提升，就会体现成“涌现”现象。</p>
<p><strong>在本文最后的最后，我想说一个题外话。我最初看到论文Beyond The Imitation Game: Quantifying And Extrapolating The Capabilities Of Language Models的时候，被它的首页吓到了，然后是一种感动油然而生：在作者署名那里，密密麻麻地列举了来自132个机构的442位作者，他们在2022年密切合作，在人类未曾涉足的前沿领域探索。</strong></p>
<p>纵观最近1-2年人工智能领域的论文，几乎没有仅仅2-3位作者署名的，都是5-6位或者10多位作者的联合署名，比如微软关于GPT-4的论文就有14位作者署名、Google关于超大模型PaLM的论文有67位作者。<strong>如今在诸多前沿领域，比如量子计算、人工智能、航天科学、核聚变等等，都需要非常复杂的多学科交汇，人类的进步不仅仅依靠一两个天才，越来越是密切的组织与合作的结果。</strong></p>
<p><img src="https://img.bibiqing.com/news/2023/1124/15_aisyfqqlo9.png" alt="OpenAI风波背后神秘项目Q-star浮出水面 谁打开了大模型的潘多拉魔盒？"></p>
<p>Beyond The Imitation Game: Quantifying And Extrapolating The Capabilities Of Language Models论文首页，密密麻麻地列举了132个机构的442位作者，感谢这些在人类前沿领域不断探索的人们。</p>
<p><strong>附录：本文的论文注释与引用</strong></p>
<p>1、 针对涌现，最核心的论文是以下两篇，可供进一步详细阅读：Google+DeepMind+Stanford等16位大牛合作的论文《Emergent Abilities of Large Language Models》（大语言模型的涌现能力）（https://openreview.net/pdf?id=yzkSU5zdwD）、UCLA 3位教授合写的论文《Emergent Analogical Reasoning in Large Language Models》（类比推理能力在大语言模型中的涌现）（https://arxiv.org/pdf/2212.09196.pdf）。</p>
<p>2、 Google联合132个机构的442位作者设计的基准测试——超越模仿游戏基准（Beyond the Imitation Game Benchmark，BIG-bench），论文链接如下：https://arxiv.org/pdf/2206.04615.pdf，测试了很多大模型的性能，都是在这个新基准之上做的。它包含了204项任务，内容多种多样，包括语言学、数学、常识推理、生物学、物理学、社会学、编程等各个方面，并且还有一个由人类专家组成的对照组，他们也同时来做这些测试任务，以跟大模型的结果做对比。</p>
<p>3、 研究如何分配总算力，如何在参数规模、训练数据量之间权衡取舍？Chinchilla模型的效果如何？详细可见DeepMind 21位作者发布的Training Compute-Optimal Language Models（https://arxiv.org/pdf/2203.15556.pdf）。DeepMind发现当前的大型语言模型存在明显训练不充分的问题，这是因为大家过于关注扩展大语言模型的参数，但没有同步增加训练数据量所导致的，所以DeepMind训练了一个参数规模更小、但训练数据量更大的优化模型 Chinchilla 来检验这一假设。</p>
<p>4、 类似DeepMind的Chinchilla，另一个“小”模型的例子，Meta推出的LLaMA，可在配备M1芯片的苹果电脑，或者单个英伟达消费级GPU上运行，并且LLaMA是开源的，详细可见这篇论文LLaMA：Open and Efficient Foundation Language Models（https://arxiv.org/pdf/2302.13971.pdf），也讨论了给定总算力预算下，该如何分配参数规模、训练数据量与训练步数/时长。</p>
<p>5、 以上是两个“小”模型的例子，而对于超大模型，Google在今年3月发布了史上最大的“通才”多模态模型PaLM，它有540B参数，PaLM-E更是有562B参数。关于这个超大模型，可见Google Research 67位作者联合署名的这篇论文：PaLM：Scaling Language Modeling with Pathways（https://arxiv.org/pdf/2204.02311.pdf）。</p>
<p>6、 微软针对GPT-4的论文，详细分析了GPT-4的各种表现，并且提出了对能力涌现的疑问，详细可见：https://arxiv.org/pdf/2303.12712.pdf。</p>
<p>7、 基于人类反馈的fine-tuning策略，OpenAI训练了InstructGPT，尽管参数规模小很多（只有1.3B），但InstructGPT比175B参数规模的GPT-3，在真实性和减少有毒输出方面表现更好，这种方法被证明是保持大语言模型与人类意图一致的潜在方法。详细可见OpenAI的论文：Training language models to follow instructions with human feedback（https://arxiv.org/pdf/2203.02155.pdf）。</p>
<p>8、 另一个通过人类反馈的强化学习（RLHF），来微调语言模型的例子是Anthropic做的，这家新公司创立于2021年，由OpenAI的早期核心员工离职创立，他们致力于解决AI“黑盒子”的问题，希望能够解释AI真正的工作原理，提升安全性。这篇论文由31位Anthropic的作者联合署名，详细可见：Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback（https://arxiv.org/pdf/2204.05862.pdf）。</p>
<p>9、 如果你想进一步研究ICL（in-context learning，上下文学习），ICL的表现大幅超越零监督学习，并给大模型高效运用提供了新的思路，但其工作机制仍有待研究。可以看这2篇：OpenAI写的：《Language Models are Few-Shot Learners》（https://arxiv.org/pdf/2005.14165.pdf）；以及华盛顿大学、Meta、Allen Institute for AI合著的论文：《Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?》（https://arxiv.org/pdf/2202.12837.pdf）。</p>
<p>10、 关于CoT，CoT（思维链，Chain of Thought）是大语言模型推理能力的重要来源之一，最早系统性提出CoT做法的，是Google Brain团队，9位作者在论文Chain of thought prompting elicits reasoning in large language models中系统性阐述了CoT，详细可见：https://arxiv.org/pdf/2201.11903.pdf。</p>
<p>11、 为何会出现U型曲线？Google在论文Inverse scaling can become U-shaped中给出了包含了不同类型的子任务，一种是真正的任务，另外一种是“干扰任务”，详细可见：https://arxiv.org/pdf/2211.02011.pdf。</p>
<p>12、 对于论证浅层语言知识，比如词法、词性、句法等知识，存储在Transformer的低层和中层；而抽象的语言知识比如语义类知识，广泛分布在Transformer的中层和高层，以下两篇论文做了深度的研究工作，这些论证研究工作对大语言模型的发展至关重要。详细可见：BERTnesia：Investigating the capture and forgetting of knowledge in BERT（https://arxiv.org/pdf/2106.02902.pdf）和Transformer Feed-Forward Layers Are Key-Value Memories（https://arxiv.org/pdf/2012.14913.pdf）。</p>
<p>13、 目前大语言模型在复杂推理方面仍然有局限性，加州大学圣芭芭拉分校5位研究者在论文Limitations of Language Models in Arithmetic and Symbolic Induction，研究了这个问题，详细可见：https://arxiv.org/pdf/2208.05051.pdf。</p>
<p>14、 新浪微博AI Lab负责人张俊林对大语言模型技术及涌现现象有过详细的综述，本文部分内容援引自他的综述，可见《由ChatGPT反思大语言模型（LLM）的技术精要》，感谢他对此做了体系化的综述。</p>
<table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Gate芝麻开门</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/gateio?ref=githubio">平台介绍</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/gateio?ref=githubio">Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的加密货币交易平台，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bitget</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bitget?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bitget?ref=githubio">Bitget的背后是一群区块链技术的早期接受者，也是区块链未来发展的信仰者，一直致力于提供安全、一站式的交易解决方案，帮助用户更聪明地交易。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bybit</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bybit?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bybit?ref=githubio">Bybit通过数字资产与传统金融的结合，引领数字资产的生态发展。提供一流的流动性，致力于打造业内最安全、公平、高效及人性化的交易服务平台。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">派网</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/pionex?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/pionex?ref=githubio">派网提供多样化的量化交易机器人，用户可依照自身交易需求和策略选择最适合的机器人。 同时派网也提供合约交易与合约网格机器人，给予更方便的合约交易体验。</a>
            </td>
        </tr>
    </tbody>
</table>

        </div>

        
        



        
        


        <footer class="post-footer">
          


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/63975/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">MVB加速器计划与CMC Labs推出Founder Track</span>
                <span class="prev-text nav-mobile">上一篇</span>
              </a>
            
              <a class="next" href="/post/64014/">
                <span class="next-text nav-default">OpenAI闹剧 一场没有赢家的科技战争</span>
                <span class="prev-text nav-mobile">下一篇</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      
        
      


      
      


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">文章目录</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#大语言模型令人震惊的理解和推理能力"><strong>大语言模型令人震惊的理解和推理能力</strong></a></li>
    <li><a href="#当我们加大模型规模时-出现的三种神奇表现"><strong>当我们加大模型规模时，</strong> <strong>出现的三种神奇表现</strong></a></li>
    <li><a href="#两种被证明具备涌现的典型能力"><strong>两种被证明具备“涌现”的典型能力：</strong></a></li>
    <li><a href="#多大的模型规模会出现涌现"><strong>多大的模型规模会出现“涌现”？</strong></a></li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  

<a href="https://www.okbtc.cn/binance?ref=githubio" class="iconfont">
  <img src="/image/logo/binance.png" width="36px" height="36px" alt="binance">
</a>

<a href="https://www.okbtc.cn/okx?ref=githubio" class="iconfont">
  <img src="/image/logo/okx.png" width="36px" height="36px" alt="okx">
</a>

<a href="https://www.okbtc.cn/htx?ref=githubio" class="iconfont">
  <img src="/image/logo/htx.png" width="36px" height="36px" alt="htx">
</a>

<a href="https://www.okbtc.cn/gateio?ref=githubio" class="iconfont">
  <img src="/image/logo/gateio.png" width="36px" height="36px" alt="gateio">
</a>

<a href="https://www.okbtc.cn/bitget?ref=githubio" class="iconfont">
  <img src="/image/logo/bitget.png" width="36px" height="36px" alt="bitget">
</a>

<a href="https://www.okbtc.cn/bybit?ref=githubio" class="iconfont">
  <img src="/image/logo/bybit.png" width="36px" height="36px" alt="bybit">
</a>

<a href="https://www.okbtc.cn/pionex?ref=githubio" class="iconfont">
  <img src="/image/logo/pionex.png" width="36px" height="36px" alt="pionex">
</a>



</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2023
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        coin
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.8b200667dc4d9618390c41639250b9c29e57ce80707352fa95af6cb67cf2371a.js" integrity="sha256-iyAGZ9xNlhg5DEFjklC5wp5XzoBwc1L6la9stnzyNxo=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







  </body>
</html>
